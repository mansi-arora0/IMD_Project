{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansi-arora0/IMD_Project/blob/main/JetVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BfXmmYb1fia"
      },
      "outputs": [],
      "source": [
        "!pip install xarray netCDF4 h5netcdf h5py matplotlib --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho0h5TOz1gXX"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        " # 2024 - 2025\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljfAq3lt1sbs"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "\n",
        "# Replace the file name with your uploaded one\n",
        "file_path = \"d1a3a20e3f4f0af74b77d6fba10275bd.nc\"\n",
        "\n",
        "ds = xr.open_dataset(file_path, decode_times=False)\n",
        "ds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukk-JHuoH7cd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert UNIX seconds to pandasâ€†datetime64\n",
        "dt = pd.to_datetime(ds.valid_time.values, unit=\"s\")\n",
        "\n",
        "# Attach that array as the coordinate\n",
        "ds = ds.assign_coords(valid_time=(\"valid_time\", dt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK56rC_sIVmo"
      },
      "outputs": [],
      "source": [
        "ds = ds.assign_coords(\n",
        "        valid_time=(\"valid_time\",\n",
        "                    pd.to_datetime(ds.valid_time.values, unit=\"s\"))\n",
        "     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tZ_Lx8LIaCv"
      },
      "outputs": [],
      "source": [
        "print(ds.valid_time.isel(valid_time=slice(0, 5)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKzK6oMQIdK-"
      },
      "outputs": [],
      "source": [
        "# Compute wind speed (in m/s)\n",
        "ws = (ds['u']**2 + ds['v']**2)**0.5\n",
        "\n",
        "# Resample to daily average wind speed\n",
        "daily_ws = ws.resample(valid_time=\"1D\").mean()\n",
        "\n",
        "# See the result\n",
        "daily_ws\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z_c4Zd5I5mt"
      },
      "outputs": [],
      "source": [
        "daily_ws = ws.resample(valid_time=\"1D\").mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtqGyyYBLetJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a date and pressure level\n",
        "date = '2024-05-01'\n",
        "level = 850  # You can also use 925\n",
        "\n",
        "daily_ws.sel(valid_time=date, pressure_level=level).plot(\n",
        "    x='longitude', y='latitude', cmap='viridis',\n",
        "    figsize=(10, 6), cbar_kwargs={'label': 'Wind Speed (m/s)'}\n",
        ")\n",
        "plt.title(f'Daily Wind Speed on {date} at {level} hPa')\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIr4ZfbwNHjN"
      },
      "outputs": [],
      "source": [
        "# Select a point (e.g., New Delhi: ~28.6Â°N, 77.2Â°E)\n",
        "lat = 28.5\n",
        "lon = 77.25\n",
        "level = 850\n",
        "\n",
        "# Get the time series\n",
        "ws_timeseries = daily_ws.sel(latitude=lat, longitude=lon, pressure_level=level, method=\"nearest\")\n",
        "\n",
        "# Plot it\n",
        "ws_timeseries.plot(figsize=(12, 4))\n",
        "plt.title(f\"Wind Speed Time Series at lat={lat}, lon={lon}, level={level}\")\n",
        "plt.ylabel(\"Wind Speed (m/s)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2UBUEknNnXB"
      },
      "outputs": [],
      "source": [
        "# Save processed data to NetCDF\n",
        "daily_ws.to_netcdf(\"daily_wind_speed.nc\")\n",
        "print(\"Saved as daily_wind_speed.nc âœ…\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A6u0CFyNqys"
      },
      "outputs": [],
      "source": [
        "print(daily_ws.valid_time.values)\n",
        "print(daily_ws.pressure_level.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53msC92LYQIe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a date and pressure level\n",
        "date  = '2024-07-15'\n",
        "level = 925\n",
        "\n",
        "daily_ws.sel(valid_time=date, pressure_level=level).plot(\n",
        "    x='longitude', y='latitude', cmap='viridis',\n",
        "    figsize=(10, 6), cbar_kwargs={'label': 'Wind Speed (m/s)'}\n",
        ")\n",
        "plt.title(f'Daily Wind Speed on {date} at {level} hPa')\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9igaJ5zbYk4D"
      },
      "outputs": [],
      "source": [
        "print(daily_ws.valid_time.values)\n",
        "print(daily_ws.pressure_level.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fxdp8lzZEqi"
      },
      "outputs": [],
      "source": [
        "pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyjLbU7PZ7dx"
      },
      "outputs": [],
      "source": [
        "#Animation of Wind Speed over a Month\n",
        "'''We'll create a GIF or animation showing wind speed maps day by day for 30 days'''\n",
        "import matplotlib.pyplot as plt\n",
        "import xarray as xr\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Select 30 days from your available time range\n",
        "dates = daily_ws.valid_time.values[:30]  # First 30 days\n",
        "level = 925  # or 850\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create an initial plot\n",
        "img = daily_ws.sel(valid_time=dates[0], pressure_level=level).plot(\n",
        "    ax=ax, x='longitude', y='latitude', cmap='viridis', add_colorbar=False\n",
        ")\n",
        "cbar = fig.colorbar(img, ax=ax, orientation='vertical', label='Wind Speed (m/s)')\n",
        "title = ax.set_title(f'Wind Speed on {str(dates[0])[:10]} at {level} hPa')\n",
        "\n",
        "# Update function for animation\n",
        "def update(i):\n",
        "    data = daily_ws.sel(valid_time=dates[i], pressure_level=level)\n",
        "    img.set_array(data.values.flatten())\n",
        "    title.set_text(f'Wind Speed on {str(dates[i])[:10]} at {level} hPa')\n",
        "\n",
        "# Animate\n",
        "anim = FuncAnimation(fig, update, frames=len(dates), interval=500)\n",
        "\n",
        "# Save as GIF (you need imagemagick or Pillow)\n",
        "anim.save('wind_animation.gif', writer='pillow')  # or writer='imagemagick'\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCT7CYn3aM4n"
      },
      "outputs": [],
      "source": [
        "import os, glob, pathlib\n",
        "\n",
        "# List GIFs in the current working directory\n",
        "print(\"Current working dir:\", pathlib.Path().absolute())\n",
        "print(\"GIFs I see here:\", glob.glob(\"*.gif\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdVbRVWJazKu"
      },
      "outputs": [],
      "source": [
        "#Comparison Plot for 2 Pressure Levels on Same Date\n",
        "date = '2024-06-15'\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "for i, level in enumerate([925, 850]):\n",
        "    data = daily_ws.sel(valid_time=date, pressure_level=level)\n",
        "    data.plot(\n",
        "        ax=axs[i], x='longitude', y='latitude', cmap='plasma',\n",
        "        cbar_kwargs={'label': 'Wind Speed (m/s)'}\n",
        "    )\n",
        "    axs[i].set_title(f'Wind Speed on {date} at {level} hPa')\n",
        "    axs[i].set_xlabel(\"Longitude\")\n",
        "    axs[i].set_ylabel(\"Latitude\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaMl19cnbLVv"
      },
      "outputs": [],
      "source": [
        "#Animation of Wind Speed over a Month\n",
        "'''We'll create a GIF or animation showing wind speed maps day by day for 30 days'''\n",
        "import matplotlib.pyplot as plt\n",
        "import xarray as xr\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Select 30 days from your available time range\n",
        "dates = daily_ws.valid_time.values[:30]  # First 30 days\n",
        "level = 850\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create an initial plot\n",
        "img = daily_ws.sel(valid_time=dates[0], pressure_level=level).plot(\n",
        "    ax=ax, x='longitude', y='latitude', cmap='viridis', add_colorbar=False\n",
        ")\n",
        "cbar = fig.colorbar(img, ax=ax, orientation='vertical', label='Wind Speed (m/s)')\n",
        "title = ax.set_title(f'Wind Speed on {str(dates[0])[:10]} at {level} hPa')\n",
        "\n",
        "# Update function for animation\n",
        "def update(i):\n",
        "    data = daily_ws.sel(valid_time=dates[i], pressure_level=level)\n",
        "    img.set_array(data.values.flatten())\n",
        "    title.set_text(f'Wind Speed on {str(dates[i])[:10]} at {level} hPa')\n",
        "\n",
        "# Animate\n",
        "anim = FuncAnimation(fig, update, frames=len(dates), interval=500)\n",
        "\n",
        "# Save as GIF (you need imagemagick or Pillow)\n",
        "anim.save('wind1_animation.gif', writer='pillow')  # or writer='imagemagick'\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX1u2IlMbcOv"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename=\"wind_animation.gif\")\n",
        "'''The animation shows the variation in wind speed at 925 hPa pressure level over a period of 30 days. Wind intensities change across the Indian subcontinent due to monsoon dynamics and pressure gradients'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGjxk_tRet61"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename=\"wind1_animation.gif\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVSDnTU6exGG"
      },
      "outputs": [],
      "source": [
        "#To calculate the average wind speed for your 2024â€“2025 data\n",
        "\n",
        "ws_2024_2025 = daily_ws.sel(valid_time=slice(\"2024-01-01\", \"2025-12-31\"))\n",
        "\n",
        "#2. Calculate the average over time\n",
        "avg_ws_2024_2025 = ws_2024_2025.mean(dim=\"valid_time\")\n",
        "\n",
        "#3. Save it\n",
        "avg_ws_2024_2025.to_netcdf(\"avg_ws_2024_2025.nc\")\n",
        "\n",
        "#4. Scaler average\n",
        "scalar_avg_ws = ws_2024_2025.mean().item()\n",
        "print(\"Overall average wind speed (2024â€“2025):\", round(scalar_avg_ws, 2), \"m/s\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WiX7Xxy3SuV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "avg_ws_2024_2025.sel(pressure_level=850).plot(\n",
        "    x='longitude', y='latitude', cmap='viridis',\n",
        "    cbar_kwargs={'label': 'Avg Wind Speed (m/s)'},\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "plt.title(\"Average Wind Speed (2024â€“2025) at 850 hPa\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9kUsMWU3yFI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2015 - 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1Eo5wSrIbA0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2017 - 2018\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NS7O8d3UOVm"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2019 - 2020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdu8qzaiV2F6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2021 - 2022\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ABn_MBzihU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rb6nLVizmiG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for file in os.listdir(\"/content\"):\n",
        "    if file.endswith(\".nc\"):\n",
        "        print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW1ItS28-E-L"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2015 - 2016\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG2K7I5eCjLw"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "#2024 - 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY2CgeJhHsLb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for file in os.listdir(\"/content\"):\n",
        "    if file.endswith(\".nc\"):\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOLKZDoUSsl-"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "\n",
        "# List your NetCDF file names (make sure these match exactly!)\n",
        "file_list = [\n",
        "    \"/content/7fc3dc956166a8e81e8d2186fea25585.nc\",   # 2015â€“2016\n",
        "    \"/content/69e2b3a22b07d506df5eaa6990c937af.nc\",   # 2017â€“2018\n",
        "    \"/content/f48a038b5b49b403f49f163404f74967.nc\",   # 2019â€“2020\n",
        "    \"/content/342854a6b62d23b9f43ce5792ee0e5c9.nc\",   # 2021â€“2022\n",
        "    \"/content/c612badfed4c054f3fa18ef4244b20e.nc\",    # 2023\n",
        "    \"/content/d1a3a20e3f4f0af74b77d6fba10275bd.nc\",   # 2024â€“2025\n",
        "]\n",
        "\n",
        "# Merge all files into one dataset\n",
        "combined_ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
        "\n",
        "# Check the contents\n",
        "combined_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJgtvlZeUtdG"
      },
      "outputs": [],
      "source": [
        "combined_ds.data_vars\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x62uVVcsZyri"
      },
      "outputs": [],
      "source": [
        "#average wind speed from 2015 to 2025:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Compute wind speed from u and v components\n",
        "wind_speed = np.sqrt(combined_ds['u']**2 + combined_ds['v']**2)\n",
        "\n",
        "# Step 2: Select data between 2015 and 2025\n",
        "ws_2015_2025 = wind_speed.sel(valid_time=slice(\"2015-01-01\", \"2025-12-31\"))\n",
        "\n",
        "# Step 3: Average over time (to get spatial wind speed map)\n",
        "avg_ws_2015_2025 = ws_2015_2025.mean(dim=\"valid_time\")\n",
        "\n",
        "# Step 4: Save to NetCDF file\n",
        "avg_ws_2015_2025.to_netcdf(\"avg_ws_2015_2025.nc\")\n",
        "\n",
        "# Step 5: Scalar average (overall single value for all years and locations)\n",
        "scalar_avg_ws = ws_2015_2025.mean().compute().item()\n",
        "print(\"Overall average wind speed (2015â€“2025):\", round(scalar_avg_ws, 2), \"m/s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-fmiYODaHg1"
      },
      "outputs": [],
      "source": [
        "print(ws_2015_2025.valid_time.min().values)\n",
        "print(ws_2015_2025.valid_time.max().values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYgXJQh0bcaH"
      },
      "outputs": [],
      "source": [
        "print(f\"Average wind speed from {ws_2015_2025.valid_time.min().values} to {ws_2015_2025.valid_time.max().values}: {round(scalar_avg_ws, 2)} m/s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "841aApGXbqA-"
      },
      "outputs": [],
      "source": [
        "#Calculate Average Wind Direction (2015â€“2025):\n",
        "# Step 1: Select u and v wind components from 2015â€“2025\n",
        "\n",
        "u_2015_2025 = combined_ds[\"u\"].sel(valid_time=slice(\"2015-01-01\", \"2025-12-31\"))\n",
        "v_2015_2025 = combined_ds[\"v\"].sel(valid_time=slice(\"2015-01-01\", \"2025-12-31\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbpkNaT6cLdb"
      },
      "outputs": [],
      "source": [
        "#Step 2: Calculate wind direction in degrees\n",
        "#Use arctangent to calculate the direction from u and v:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate direction in radians, then convert to degrees\n",
        "wind_dir_rad = np.arctan2(u_2015_2025, v_2015_2025)\n",
        "wind_dir_deg = (np.degrees(wind_dir_rad) + 360) % 360  # Convert to degrees and normalize 0â€“360Â°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMRkLGZCcO60"
      },
      "outputs": [],
      "source": [
        "#Step 3: Average over time\n",
        "\n",
        "avg_wind_dir_2015_2025 = wind_dir_deg.mean(dim=\"valid_time\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODBKcxBvcVPe"
      },
      "outputs": [],
      "source": [
        "#Step 4: Convert to scalar average for overall value (optional)\n",
        "#This gives a single overall wind direction, averaged over the entire 11-year period.\n",
        "\n",
        "scalar_avg_dir = avg_wind_dir_2015_2025.mean().compute().item()\n",
        "print(f\"Average wind direction (2015â€“2025): {round(scalar_avg_dir, 2)} degrees\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glyaau6rcgjw"
      },
      "outputs": [],
      "source": [
        "#convert average wind speed to knots\n",
        "\n",
        "mps_speed = 7.66\n",
        "knots_speed = mps_speed * 1.94384\n",
        "print(\"Average wind speed in knots:\", round(knots_speed, 2), \"knots\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7b0ujgpjPd1"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0-B7xhhjluq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for file in os.listdir(\"/content\"):\n",
        "    if file.endswith(\".nc\"):\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI4IMoWVkG9r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Vn8kWjqtpg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4dlG_44rhw3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for file in os.listdir(\"/content\"):\n",
        "    if file.endswith(\".nc\"):\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riavEIG3r0vE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Extract u and v wind components (you can adjust pressure level if needed)\n",
        "u = combined_ds['u']\n",
        "v = combined_ds['v']\n",
        "\n",
        "# 2. Calculate wind speed: sqrt(uÂ² + vÂ²)\n",
        "wind_speed = np.sqrt(u**2 + v**2)\n",
        "\n",
        "# 3. Compute average wind speed over time\n",
        "avg_wind_speed = wind_speed.mean(dim='valid_time')\n",
        "print(\"âœ… Average Wind Speed (2015â€“2025) calculated.\")\n",
        "\n",
        "# 4. Compute scalar average wind speed (a single number)\n",
        "scalar_avg_wind_speed = float(wind_speed.mean().values)\n",
        "print(\"ðŸŒ¬ï¸ Scalar Average Wind Speed (2015â€“2025):\", round(scalar_avg_wind_speed, 2), \"m/s\")\n",
        "\n",
        "# 5. Convert to knots (1 m/s = 1.94384 knots)\n",
        "scalar_avg_knots = scalar_avg_wind_speed * 1.94384\n",
        "print(\"â›µ Scalar Average Wind Speed (in knots):\", round(scalar_avg_knots, 2), \"knots\")\n",
        "\n",
        "# 6. Calculate wind direction in degrees\n",
        "wind_direction = (np.arctan2(u, v) * 180 / np.pi) % 360\n",
        "avg_wind_direction = wind_direction.mean(dim='valid_time')\n",
        "scalar_avg_direction = float(wind_direction.mean().values)\n",
        "print(\"ðŸ§­ Scalar Average Wind Direction (2015â€“2025):\", round(scalar_avg_direction, 2), \"Â°\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eqkET1Zr404"
      },
      "outputs": [],
      "source": [
        "'''Define Wind Speed Regions and Calculate Area Covered\n",
        "Weâ€™ll use your average wind speed (in knots) and define 3 regions:\n",
        "30â€“40 knots and 40â€“50 knots and 50+ knots\n",
        "Then, weâ€™ll estimate how much area (in kmÂ²) each region covers.\n",
        " '''\n",
        "\n",
        "#First, define the speed regions:\n",
        "# 1. Convert the average wind speed to knots\n",
        "avg_wind_speed_knots = avg_wind_speed * 1.94384\n",
        "\n",
        "# 2. Define masks for each speed region\n",
        "speed_regions = {\n",
        "    '30-40 knots': (avg_wind_speed_knots >= 30) & (avg_wind_speed_knots < 40),\n",
        "    '40-50 knots': (avg_wind_speed_knots >= 40) & (avg_wind_speed_knots < 50),\n",
        "    '50+ knots': (avg_wind_speed_knots >= 50)\n",
        "}\n",
        "\n",
        "#Step 2: Estimate Area of One Grid Cell\n",
        "!pip install haversine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlPKZdYCvhZe"
      },
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "\n",
        "# Use two points from your grid to estimate cell size\n",
        "lat1 = float(avg_wind_speed.latitude[0])\n",
        "lat2 = float(avg_wind_speed.latitude[1])\n",
        "lon1 = float(avg_wind_speed.longitude[0])\n",
        "lon2 = float(avg_wind_speed.longitude[1])\n",
        "\n",
        "# Calculate width and height\n",
        "width_km = haversine((lat1, lon1), (lat1, lon2), unit=Unit.KILOMETERS)\n",
        "height_km = haversine((lat1, lon1), (lat2, lon1), unit=Unit.KILOMETERS)\n",
        "cell_area_km2 = width_km * height_km\n",
        "\n",
        "print(f\"ðŸ§¾ Estimated area of one grid cell: {cell_area_km2:.2f} kmÂ²\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKKlYxeEvvZi"
      },
      "outputs": [],
      "source": [
        "#Step 3: Calculate Total Area for Each Region\n",
        "\n",
        "for label, mask in speed_regions.items():\n",
        "    num_cells = int(mask.sum().compute().item())   # â† fixed\n",
        "    total_area = num_cells * cell_area_km2\n",
        "    print(f\"\\nðŸŒªï¸ Wind Region: {label}\")\n",
        "    print(f\"   â–ª Grid Cells: {num_cells}\")\n",
        "    print(f\"   â–ª Area Covered: {total_area:.2f} kmÂ²\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aqDj1AYv98w"
      },
      "outputs": [],
      "source": [
        "#Step-by-step Python code to plot wind speed regions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Meshgrid for plotting\n",
        "lon2d, lat2d = np.meshgrid(u0.longitude, u0.latitude)\n",
        "\n",
        "# Define masks again (just for clarity)\n",
        "region_30_40 = (speed_knots >= 30) & (speed_knots < 40)\n",
        "region_40_50 = (speed_knots >= 40) & (speed_knots < 50)\n",
        "region_50_plus = speed_knots >= 50\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([40, 55, -5, 15], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "# Plot regions\n",
        "plt.contourf(lon2d, lat2d, region_30_40, levels=[0.5, 1.5], colors='yellow', alpha=0.6, transform=ccrs.PlateCarree(), label='30â€“40 knots')\n",
        "plt.contourf(lon2d, lat2d, region_40_50, levels=[0.5, 1.5], colors='orange', alpha=0.6, transform=ccrs.PlateCarree(), label='40â€“50 knots')\n",
        "plt.contourf(lon2d, lat2d, region_50_plus, levels=[0.5, 1.5], colors='red', alpha=0.6, transform=ccrs.PlateCarree(), label='50+ knots')\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Wind Speed Regions over Somali Coast (First Time Frame)\", fontsize=14)\n",
        "yellow_patch = plt.Line2D([0], [0], marker='s', color='w', label='30â€“40 knots', markerfacecolor='yellow', markersize=10)\n",
        "orange_patch = plt.Line2D([0], [0], marker='s', color='w', label='40â€“50 knots', markerfacecolor='orange', markersize=10)\n",
        "red_patch = plt.Line2D([0], [0], marker='s', color='w', label='50+ knots', markerfacecolor='red', markersize=10)\n",
        "plt.legend(handles=[yellow_patch, orange_patch, red_patch], loc='lower left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAQ5err40HhD"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 0. Mount Google Drive (skip if already mounted in your session)\n",
        "# ============================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# ============================================================\n",
        "# 1. Imports\n",
        "# ============================================================\n",
        "import glob, os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from haversine import haversine, Unit\n",
        "\n",
        "# ============================================================\n",
        "# 2. Load & combine all NetCDF files from your Drive folder\n",
        "# ============================================================\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"     # << adjust if your folder path differs\n",
        "nc_files = sorted(glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Pick variable names (update if yours differ)\n",
        "u_name = \"u\"      # e.g., 'u'  or 'u100'\n",
        "v_name = \"v\"      # e.g., 'v'  or 'v100'\n",
        "\n",
        "# ============================================================\n",
        "# 3. Select your custom region  (North 30, South -15, West 75, East 30)\n",
        "# ============================================================\n",
        "u_reg = ds[u_name].sel(latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v_reg = ds[v_name].sel(latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# ============================================================\n",
        "# 4. Choose pressure level (comment out if data is already 2â€‘D)\n",
        "# ============================================================\n",
        "if \"pressure_level\" in u_reg.dims:\n",
        "    PL = 850                 # pick 850â€¯hPa; change to 925 or 100 for 100â€¯m if needed\n",
        "    u_reg = u_reg.sel(pressure_level=PL)\n",
        "    v_reg = v_reg.sel(pressure_level=PL)\n",
        "\n",
        "# ============================================================\n",
        "# 5. Select a time index (t = 0 is first date)\n",
        "# ============================================================\n",
        "t = 0                       # change to another index for another date\n",
        "u0 = u_reg.isel(valid_time=t)\n",
        "v0 = v_reg.isel(valid_time=t)\n",
        "\n",
        "# 2â€‘D lon/lat grids\n",
        "lon2d, lat2d = np.meshgrid(u0.longitude, u0.latitude)\n",
        "\n",
        "# ============================================================\n",
        "# 6. Wind speed (mâ€¯sâ»Â¹) and knots\n",
        "# ============================================================\n",
        "speed0 = np.sqrt(u0**2 + v0**2)\n",
        "speed_knots = speed0 * 1.94384   # 1 m/s = 1.94384 knots\n",
        "\n",
        "# ============================================================\n",
        "# 7. Wind direction (Â° from which wind blows)\n",
        "# ============================================================\n",
        "direction0 = (np.degrees(np.arctan2(u0, v0)) + 360) % 360\n",
        "\n",
        "# ============================================================\n",
        "# 8. Estimate area of one grid cell (kmÂ²)\n",
        "# ============================================================\n",
        "def grid_area_km2(lat_a, lat_b, lon_a, lon_b):\n",
        "    w = haversine((lat_a, lon_a), (lat_a, lon_b), unit=Unit.KILOMETERS)\n",
        "    h = haversine((lat_a, lon_a), (lat_b, lon_a), unit=Unit.KILOMETERS)\n",
        "    return w * h\n",
        "\n",
        "cell_area = grid_area_km2(float(lat2d[0,0]), float(lat2d[1,0]),\n",
        "                          float(lon2d[0,0]), float(lon2d[0,1]))\n",
        "\n",
        "# ============================================================\n",
        "# 9. Speedâ€‘region masks & area / direction stats\n",
        "# ============================================================\n",
        "thresholds = [30, 40, 50]           # knots\n",
        "for thr in thresholds:\n",
        "    mask = speed_knots > thr\n",
        "    num_cells = int(mask.sum().compute().item())      # safe for Dask\n",
        "    total_area = num_cells * cell_area\n",
        "\n",
        "    if num_cells > 0:\n",
        "        dirs = direction0.where(mask)\n",
        "        rad  = np.deg2rad(dirs)\n",
        "        mean_dir = (np.arctan2(np.nanmean(np.sin(rad)),\n",
        "                               np.nanmean(np.cos(rad))) * 180/np.pi) % 360\n",
        "        dir_text = f\"{mean_dir:.2f}Â°\"\n",
        "    else:\n",
        "        dir_text = \"No data\"\n",
        "\n",
        "    print(f\"\\nðŸŒªï¸  Wind Region > {thr} kt\")\n",
        "    print(f\"   â–ª Grid cells : {num_cells}\")\n",
        "    print(f\"   â–ª Area       : {total_area:,.0f} kmÂ²\")\n",
        "    print(f\"   â–ª Avg dir    : {dir_text}\")\n",
        "\n",
        "# ============================================================\n",
        "# 10. Plot wind vectors coloured by speed\n",
        "# ============================================================\n",
        "plt.figure(figsize=(11, 8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 30])\n",
        "ax.coastlines(); ax.add_feature(cfeature.BORDERS)\n",
        "ax.add_feature(cfeature.LAND, facecolor=\"lightgray\"); ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "q = ax.quiver(lon2d, lat2d, u0.values, v0.values, speed0.values,\n",
        "              scale=700, cmap=\"viridis\")\n",
        "plt.colorbar(q, label=\"Wind speed (mâ€¯sâ»Â¹)\")\n",
        "date_str = str(u0.valid_time.values)[:10]\n",
        "plt.title(f\"Wind vectors at {PL if 'pressure_level' in u_reg.dims else 'model level'}â€‰hPa â€¢ {date_str}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOHkAA6d3UgY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckJWrv1G4iza"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T94yrpLB4mqo"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from haversine import haversine, Unit\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Folder with your NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".nc\")]\n",
        "\n",
        "# Combine multiple NetCDF files\n",
        "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
        "\n",
        "# Use u and v components at 850 hPa level\n",
        "pressure_level = 850\n",
        "u = ds['u'].sel(pressure_level=pressure_level)\n",
        "v = ds['v'].sel(pressure_level=pressure_level)\n",
        "\n",
        "# Somali Jet region: N=15, S=-15, W=30, E=75\n",
        "u_region = u.sel(latitude=slice(15, -15), longitude=slice(30, 75))\n",
        "v_region = v.sel(latitude=slice(15, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Use first time frame\n",
        "u0 = u_region.isel(valid_time=0)\n",
        "v0 = v_region.isel(valid_time=0)\n",
        "speed0 = np.sqrt(u0**2 + v0**2)\n",
        "\n",
        "# Convert to knots\n",
        "speed_knots = speed0 * 1.94384\n",
        "\n",
        "# Estimate grid cell area in kmÂ²\n",
        "def estimate_grid_area(lat1, lat2, lon1, lon2):\n",
        "    p1, p2 = (lat1, lon1), (lat2, lon1)\n",
        "    p3 = (lat1, lon2)\n",
        "    width = haversine(p1, p3, unit=Unit.KILOMETERS)\n",
        "    height = haversine(p1, p2, unit=Unit.KILOMETERS)\n",
        "    return width * height\n",
        "\n",
        "grid_area = estimate_grid_area(\n",
        "    float(u0.latitude[0]), float(u0.latitude[1]),\n",
        "    float(u0.longitude[0]), float(u0.longitude[1])\n",
        ")\n",
        "\n",
        "# Wind direction\n",
        "direction_deg = (np.arctan2(u0, v0) * 180 / np.pi) % 360\n",
        "\n",
        "# Analyze by speed thresholds\n",
        "thresholds = [30, 40, 50]\n",
        "for thresh in thresholds:\n",
        "    mask = speed_knots > thresh\n",
        "    num_cells = mask.sum().compute().item()\n",
        "    area = num_cells * grid_area\n",
        "\n",
        "    dir_masked = direction_deg.where(mask)\n",
        "    radians = np.deg2rad(dir_masked)\n",
        "    mean_sin = np.nanmean(np.sin(radians))\n",
        "    mean_cos = np.nanmean(np.cos(radians))\n",
        "    mean_dir = (np.arctan2(mean_sin, mean_cos) * 180 / np.pi) % 360\n",
        "\n",
        "    print(f\"\\nðŸŒªï¸ Wind Region: {thresh}+ knots\")\n",
        "    print(f\"   â–ª Grid Cells: {num_cells}\")\n",
        "    print(f\"   â–ª Area Covered: {area:.2f} kmÂ²\")\n",
        "    print(f\"   â–ª Avg Direction: {mean_dir:.2f}Â°\")\n",
        "\n",
        "# Plot wind vectors\n",
        "lon2d, lat2d = np.meshgrid(u0.longitude, u0.latitude)\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 15], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "plt.quiver(lon2d, lat2d, u0.values, v0.values, speed0.values, scale=700)\n",
        "plt.colorbar(label='Wind Speed (m/s)')\n",
        "plt.title(f\"Wind Vectors at 850 hPa â€¢ {str(u.valid_time.values[0])[:10]}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTtDYqaF6eg3"
      },
      "outputs": [],
      "source": [
        "'''Track and visualize how wind evolves from Mayâ€“August each year using:\n",
        "Wind speeds (esp. >30 knots)\n",
        "Area covered\n",
        "Average wind direction\n",
        "Animated daily maps'''\n",
        "\n",
        "#ðŸ” Step 1: Loop Over Dates & Track Key Stats\n",
        "'''We will calculate for each day:\n",
        "Total area covered by wind speed > 30 knots\n",
        "Average direction in that region'''\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from haversine import haversine, Unit\n",
        "\n",
        "# Correct your latitude and longitude slicing:\n",
        "lat_range = slice(30, -15)        # From North to South\n",
        "lon_range = slice(30, 75)         # From East to West\n",
        "\n",
        "\n",
        "# Load your merged dataset (replace with your actual dataset)\n",
        "ds = xr.open_dataset(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "\n",
        "# Select wind components\n",
        "# Use 925 hPa or 850 hPa (whichever you prefer or want to compare)\n",
        "u = ds['u'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v = ds['v'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "time = ds['valid_time']\n",
        "\n",
        "# Estimate area of one grid cell\n",
        "def estimate_grid_area(lat1, lat2, lon1, lon2):\n",
        "    p1 = (lat1, lon1)\n",
        "    p2 = (lat2, lon1)\n",
        "    p3 = (lat1, lon2)\n",
        "    width = haversine(p1, p3, unit=Unit.KILOMETERS)\n",
        "    height = haversine(p1, p2, unit=Unit.KILOMETERS)\n",
        "    return width * height\n",
        "\n",
        "grid_area = estimate_grid_area(\n",
        "    float(u.latitude[0]), float(u.latitude[1]),\n",
        "    float(u.longitude[0]), float(u.longitude[1])\n",
        ")\n",
        "\n",
        "# Time loop\n",
        "records = []\n",
        "\n",
        "\n",
        "for i in range(len(time)):\n",
        "    u0 = u.isel(valid_time=i)\n",
        "    v0 = v.isel(valid_time=i)\n",
        "\n",
        "    speed = np.sqrt(u0**2 + v0**2)\n",
        "    speed_knots = speed * 1.94384\n",
        "    # Compute wind direction in degrees (meteorological: from where wind is coming)\n",
        "    wind_dir = (np.degrees(np.arctan2(-u0.values, -v0.values)) + 360) % 360\n",
        "    #direction_deg = (np.arctan2(u0, v0) * 180 / np.pi) % 360\n",
        "\n",
        "    # Mask where speed > 30 knots\n",
        "    mask = speed_knots > 30\n",
        "    cell_count = mask.sum().item()\n",
        "    area_km2 = cell_count * grid_area\n",
        "\n",
        "    # Calculate average wind direction\n",
        "    if np.sum(mask) == 0:\n",
        "       mean_dir_deg = \"N/A\"\n",
        "    else:\n",
        "       radians = np.radians(wind_dir[mask])\n",
        "       mean_sin = np.nanmean(np.sin(radians))\n",
        "       mean_cos = np.nanmean(np.cos(radians))\n",
        "       mean_dir = np.arctan2(mean_sin, mean_cos)\n",
        "       mean_dir_deg = (np.degrees(mean_dir) + 360) % 360\n",
        "       mean_dir_deg = round(mean_dir_deg, 2)\n",
        "\n",
        "\n",
        "    records.append({\n",
        "        \"date\": str(time[i].values)[:10],\n",
        "        \"area_km2\": area_km2,\n",
        "        \"avg_direction\": mean_dir\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "df.to_csv(\"somali_jet_stats.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCcyF2F7I1Z0"
      },
      "outputs": [],
      "source": [
        "!pip install haversine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R09nS9HeP0eG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted(glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "print(\"Files found:\", nc_files)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1U91TfiQzSp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4t3QFN5SHac"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Set the correct path\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"  # <-- update this\n",
        "\n",
        "# Check\n",
        "if os.path.exists(folder_path):\n",
        "    print(\"âœ… Folder exists:\", folder_path)\n",
        "    print(\"ðŸ“‚ Files in folder:\", os.listdir(folder_path))\n",
        "    print(\"ðŸ” .nc files found:\", glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "else:\n",
        "    print(\"âŒ Folder not found:\", folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksxPehqxUAni"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Use your verified folder path here:\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"  # Replace with actual path\n",
        "\n",
        "# Get all .nc files\n",
        "nc_files = sorted(glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "print(f\"âœ… Found {len(nc_files)} .nc files\")\n",
        "\n",
        "# Combine all datasets\n",
        "combined_ds = xr.open_mfdataset(nc_files, combine='by_coords')\n",
        "\n",
        "# (Optional) Save it for quick reuse later\n",
        "combined_ds.to_netcdf(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "print(\"ðŸ’¾ Combined dataset saved as 'combined_wind.nc'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt1r4709Ww47"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1gBhMSUUmKA"
      },
      "outputs": [],
      "source": [
        "'''ðŸŽ¥ Goal: Create Daily Wind Vector Map Animation\n",
        "Weâ€™ll:\n",
        "\n",
        "Plot wind vectors (arrows) on a map for each day.\n",
        "\n",
        "Show wind speed magnitude with color.\n",
        "\n",
        "Save as a video (.mp4) or animated .gif.'''\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Load combined dataset\n",
        "ds = xr.open_dataset(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "\n",
        "# Select wind components at 925 hPa\n",
        "u = ds['u'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v = ds['v'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "time = ds['valid_time']\n",
        "\n",
        "# Subsample grid (optional, for clarity in animation)\n",
        "stride = 3  # Adjust for fewer/more arrows\n",
        "\n",
        "lats = u.latitude.values[::stride]\n",
        "lons = u.longitude.values[::stride]\n",
        "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "quiver = None\n",
        "title = ax.set_title(\"\", fontsize=14)\n",
        "\n",
        "# Animation function\n",
        "def update(i):\n",
        "    global quiver\n",
        "    ax.clear()\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "\n",
        "    u0 = u.isel(valid_time=i).values[::stride, ::stride]\n",
        "    v0 = v.isel(valid_time=i).values[::stride, ::stride]\n",
        "    speed = np.sqrt(u0**2 + v0**2)\n",
        "\n",
        "    # Plot arrows\n",
        "    quiver = ax.quiver(lon_grid, lat_grid, u0, v0, speed,\n",
        "                       cmap='plasma', scale=700, width=0.003,\n",
        "                       transform=ccrs.PlateCarree())\n",
        "\n",
        "    ax.set_title(f\"Wind Vectors | Date: {str(time[i].values)[:10]}\", fontsize=14)\n",
        "\n",
        "# Create animation\n",
        "anim = FuncAnimation(fig, update, frames=len(time), interval=300)\n",
        "\n",
        "# Save as MP4\n",
        "anim.save(\"/content/drive/MyDrive/wind_animation.mp4\", writer=\"ffmpeg\", dpi=150)\n",
        "print(\"âœ… Animation saved to Google Drive as 'wind_animation.mp4'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyZ3a90Yds3V"
      },
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.feature as cfeature\n",
        "import numpy as np\n",
        "!pip install cartopy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnJ5BoVfXNwO"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ 1. Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# â”€â”€ 2. Load dataset (already combined) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ds = xr.open_dataset(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "\n",
        "# 925â€¯orâ€¯850â€¯hPa â€“ pick one\n",
        "u_all = ds['u'].sel(pressure_level=850 , latitude=slice(30, -15),\n",
        "                                        longitude=slice(30, 75))\n",
        "v_all = ds['v'].sel(pressure_level=850 , latitude=slice(30, -15),\n",
        "                                        longitude=slice(30, 75))\n",
        "time = u_all.valid_time        # common time coordinate\n",
        "\n",
        "# â”€â”€ 3. Make a lon/lat grid (subâ€‘sample for clarity) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "stride = 3                                # arrows every 3 gridâ€‘points\n",
        "lon2d, lat2d = np.meshgrid(u_all.longitude.values[::stride],\n",
        "                           u_all.latitude .values[::stride])\n",
        "\n",
        "# â”€â”€ 4. Set up the figure & basemap (draw only once) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax  = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "ax.add_feature(cfeature.LAND , facecolor='lightgray')\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "# First frameâ€™s vectors just to initialise the artist\n",
        "u0 = u_all.isel(valid_time=0).values[::stride, ::stride]\n",
        "v0 = v_all.isel(valid_time=0).values[::stride, ::stride]\n",
        "speed0 = np.sqrt(u0**2 + v0**2)\n",
        "quiv = ax.quiver(lon2d, lat2d, u0, v0, speed0,\n",
        "                 cmap='viridis', scale=700, width=0.003,\n",
        "                 transform=ccrs.PlateCarree())\n",
        "title = ax.set_title(f\"Wind Vectors â€¢ {str(time[0].values)[:10]}\")\n",
        "\n",
        "# â”€â”€ 5. Update function for animation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def update(frame):\n",
        "    u_plot = u_all.isel(valid_time=frame).values[::stride, ::stride]\n",
        "    v_plot = v_all.isel(valid_time=frame).values[::stride, ::stride]\n",
        "    speed  = np.sqrt(u_plot**2 + v_plot**2)\n",
        "\n",
        "    # update quiver object inâ€‘place (fast!)\n",
        "    quiv.set_UVC(u_plot, v_plot, speed)\n",
        "    title.set_text(f\"Wind Vectors â€¢ {str(time[frame].values)[:10]}\")\n",
        "    return quiv, title\n",
        "\n",
        "# â”€â”€ 6. Build & save animation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "anim = animation.FuncAnimation(fig, update,\n",
        "                               frames=len(time),\n",
        "                               interval=300, blit=False)\n",
        "\n",
        "mp4_path = \"/content/drive/MyDrive/wind_animation_2015_2025.mp4\"\n",
        "anim.save(mp4_path, writer='ffmpeg', dpi=150)\n",
        "print(\"âœ… Animation saved:\", mp4_path)\n",
        "\n",
        "# â”€â”€ 7. Show inline preview (JSÂ animation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "HTML(anim.to_jshtml())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPw4_z52ddEo"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "file_list = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "\n",
        "# Check files are found\n",
        "if not file_list:\n",
        "    print(\"âŒ No .nc files found in:\", folder_path)\n",
        "else:\n",
        "    print(\"âœ… Files found:\", file_list)\n",
        "\n",
        "# Combine and save\n",
        "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
        "ds.to_netcdf(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "print(\"âœ… combined_wind.nc saved to Drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEWA-13DjM6a"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ 0. Install cartopy (first run only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# !pip install cartopy --quiet\n",
        "\n",
        "# â”€â”€ 1. Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import os, glob\n",
        "\n",
        "# â”€â”€ 2. Mount Google Drive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# â”€â”€ 3. Combine yearly files once (skip if combined_wind.nc already) â”€â”€â”€\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "combined_path = \"/content/drive/MyDrive/combined_wind.nc\"\n",
        "\n",
        "if not os.path.exists(combined_path):\n",
        "    nc_files = sorted(glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "    if not nc_files:\n",
        "        raise FileNotFoundError(\"No .nc files found in wind_data folder!\")\n",
        "    ds_tmp = xr.open_mfdataset(nc_files, combine='by_coords')\n",
        "    ds_tmp.to_netcdf(combined_path)\n",
        "    print(\"âœ… combined_wind.nc saved\")\n",
        "\n",
        "# â”€â”€ 4. Load dataset & select region/level â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ds = xr.open_dataset(combined_path)\n",
        "\n",
        "pressure_level = 850  # choose 850â€¯hPa\n",
        "u = ds[\"u\"].sel(pressure_level=pressure_level,\n",
        "                latitude=slice(30, -15),  # Nâ†’S\n",
        "                longitude=slice(30, 75))  # Eâ†’W\n",
        "v = ds[\"v\"].sel(pressure_level=pressure_level,\n",
        "                latitude=slice(30, -15),\n",
        "                longitude=slice(30, 75))\n",
        "time = u.valid_time\n",
        "\n",
        "# â”€â”€ 5. Prep meshgrid (subâ€‘sample for clarity) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "stride = 3\n",
        "lon2d, lat2d = np.meshgrid(u.longitude.values[::stride],\n",
        "                           u.latitude .values[::stride])\n",
        "\n",
        "# â”€â”€ 6. Set up figure & static basemap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax  = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "ax.add_feature(cfeature.LAND , facecolor='lightgray')\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "# Initialise quiver with first frame\n",
        "u0 = u.isel(valid_time=0).values[::stride, ::stride]\n",
        "v0 = v.isel(valid_time=0).values[::stride, ::stride]\n",
        "spd0 = np.sqrt(u0**2 + v0**2)\n",
        "quiv = ax.quiver(lon2d, lat2d, u0, v0, spd0,\n",
        "                 cmap='viridis', scale=700, width=0.003)\n",
        "title = ax.set_title(f\"Wind Vectors â€¢ {str(time.values[0])[:10]}\")\n",
        "\n",
        "# â”€â”€ 7. Animation update function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def update(frame):\n",
        "    global quiv\n",
        "    # Remove previous arrows safely\n",
        "    for coll in list(ax.collections):\n",
        "        try:\n",
        "            coll.remove()\n",
        "        except ValueError:\n",
        "            pass\n",
        "    if quiv:\n",
        "        try:\n",
        "            quiv.remove()\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    u_plot = u.isel(valid_time=frame).values[::stride, ::stride]\n",
        "    v_plot = v.isel(valid_time=frame).values[::stride, ::stride]\n",
        "    spd    = np.sqrt(u_plot**2 + v_plot**2)\n",
        "\n",
        "    quiv = ax.quiver(lon2d, lat2d, u_plot, v_plot, spd,\n",
        "                     cmap='viridis', scale=700, width=0.003)\n",
        "    title.set_text(f\"Wind Vectors â€¢ {str(time.values[frame])[:10]}\")\n",
        "    return quiv, title\n",
        "\n",
        "# â”€â”€ 8. Build & save animation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "anim = animation.FuncAnimation(fig, update,\n",
        "                               frames=len(time),\n",
        "                               interval=300)\n",
        "\n",
        "mp4_out = \"/content/drive/MyDrive/wind_animation_2015_2025.mp4\"\n",
        "anim.save(mp4_out, writer='ffmpeg', dpi=150)\n",
        "print(\"ðŸŽ¥ Saved:\", mp4_out)\n",
        "\n",
        "# â”€â”€ 9. Inline preview in notebook (JS/HTML5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "HTML(anim.to_jshtml())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aylOdA5NqAoR"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8f3H2a5jg1k"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load all NetCDF files from Drive\n",
        "import os\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select wind components and region\n",
        "u_all = ds['u'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v_all = ds['v'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Step 3: Subsample to reduce size (every 5th lat/lon and first 30 time steps)\n",
        "u_sub = u_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "v_sub = v_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "\n",
        "# Step 4: Flatten and stack data for clustering\n",
        "u_flat = u_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "v_flat = v_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "\n",
        "# Remove NaNs\n",
        "mask = ~np.isnan(u_flat) & ~np.isnan(v_flat)\n",
        "u_clean = u_flat[mask]\n",
        "v_clean = v_flat[mask]\n",
        "\n",
        "X = np.column_stack([u_clean, v_clean])  # shape: (n_samples, 2)\n",
        "\n",
        "# Step 5: Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Step 6: Calculate average speed & direction of each cluster\n",
        "print(\"ðŸ“Š Cluster Summary:\")\n",
        "for i, (u_c, v_c) in enumerate(centroids):\n",
        "    speed = np.sqrt(u_c**2 + v_c**2)\n",
        "    direction_rad = np.arctan2(u_c, v_c)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "    print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "# Optional: visualize\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.quiver([0]*len(centroids), [0]*len(centroids), centroids[:, 0], centroids[:, 1],\n",
        "           angles='xy', scale_units='xy', scale=1, color='r')\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(-10, 10)\n",
        "plt.title(\"Wind Cluster Centers (Vector Plot)\")\n",
        "plt.xlabel(\"U component (m/s)\")\n",
        "plt.ylabel(\"V component (m/s)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdclkRYmsRpW"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load all NetCDF files from Drive\n",
        "import os\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select wind components and region\n",
        "u_all = ds['u'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v_all = ds['v'].sel(pressure_level=925, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Step 3: Subsample to reduce size (every 5th lat/lon and first 30 time steps)\n",
        "u_sub = u_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "v_sub = v_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "\n",
        "# Step 4: Flatten and stack data for clustering\n",
        "u_flat = u_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "v_flat = v_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "\n",
        "# Remove NaNs\n",
        "mask = ~np.isnan(u_flat) & ~np.isnan(v_flat)\n",
        "u_clean = u_flat[mask]\n",
        "v_clean = v_flat[mask]\n",
        "\n",
        "X = np.column_stack([u_clean, v_clean])  # shape: (n_samples, 2)\n",
        "\n",
        "# Step 5: Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Step 6: Calculate average speed & direction of each cluster\n",
        "print(\"ðŸ“Š Cluster Summary:\")\n",
        "for i, (u_c, v_c) in enumerate(centroids):\n",
        "    speed = np.sqrt(u_c**2 + v_c**2)\n",
        "    direction_rad = np.arctan2(u_c, v_c)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "    print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "# Optional: visualize\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.quiver([0]*len(centroids), [0]*len(centroids), centroids[:, 0], centroids[:, 1],\n",
        "           angles='xy', scale_units='xy', scale=1, color='r')\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(-10, 10)\n",
        "plt.title(\"Wind Cluster Centers (Vector Plot)\")\n",
        "plt.xlabel(\"U component (m/s)\")\n",
        "plt.ylabel(\"V component (m/s)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAwfkFVujrCq"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "file_list = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "\n",
        "# Check files are found\n",
        "if not file_list:\n",
        "    print(\"âŒ No .nc files found in:\", folder_path)\n",
        "else:\n",
        "    print(\"âœ… Files found:\", file_list)\n",
        "\n",
        "# Combine and save\n",
        "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
        "ds.to_netcdf(\"/content/drive/MyDrive/combined_wind.nc\")\n",
        "print(\"âœ… combined_wind.nc saved to Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfndHh8OkFn-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiYnHscVkP9Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Set the correct path\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"  # <-- update this\n",
        "\n",
        "# Check\n",
        "if os.path.exists(folder_path):\n",
        "    print(\"âœ… Folder exists:\", folder_path)\n",
        "    print(\"ðŸ“‚ Files in folder:\", os.listdir(folder_path))\n",
        "    print(\"ðŸ” .nc files found:\", glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "else:\n",
        "    print(\"âŒ Folder not found:\", folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3tR_0W1mwWK"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYjCz43an9d-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "file_list = [\"/content/drive/MyDrive/wind_data/\" + f for f in os.listdir(\"/content/drive/MyDrive/wind_data\") if f.endswith(\".nc\")]\n",
        "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
        "u = ds['u'].sel(pressure_level=850)\n",
        "v = ds['v'].sel(pressure_level=850)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O99SmaNTqolo"
      },
      "outputs": [],
      "source": [
        "print(\"labels.shape =\", labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L599UzjwtetX"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of dominant_cluster:\", dominant_cluster.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-TYhwgVtvfU"
      },
      "outputs": [],
      "source": [
        "print(\"lat2d shape:\", lat2d.shape)\n",
        "print(\"lon2d shape:\", lon2d.shape)\n",
        "print(\"dominant_cluster shape:\", dominant_cluster.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYmFVUDKkiHQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Step 1: Load all NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select wind components and Somali Jet region\n",
        "u_all = ds['u'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v_all = ds['v'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Step 3: Subsample to reduce data size (every 5th point in lat/lon, and first 30 time steps)\n",
        "u_sub = u_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "v_sub = v_all.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5), valid_time=slice(0, 30))\n",
        "\n",
        "# Step 4: Flatten for clustering\n",
        "u_flat = u_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "v_flat = v_sub.stack(sample=(\"valid_time\", \"latitude\", \"longitude\")).values\n",
        "\n",
        "# Remove NaNs\n",
        "mask = ~np.isnan(u_flat) & ~np.isnan(v_flat)\n",
        "u_clean = u_flat[mask]\n",
        "v_clean = v_flat[mask]\n",
        "\n",
        "X = np.column_stack([u_clean, v_clean])  # shape: (n_samples, 2)\n",
        "\n",
        "# Step 5: Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Step 6: Print summary of clusters\n",
        "print(\"ðŸ“Š Cluster Summary:\")\n",
        "for i, (u_c, v_c) in enumerate(centroids):\n",
        "    speed = np.sqrt(u_c**2 + v_c**2)\n",
        "    direction_rad = np.arctan2(u_c, v_c)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "    print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "# Step 7: Reshape labels to 3D and find dominant cluster at each grid cell\n",
        "n_time = u_sub.valid_time.size\n",
        "n_lat = u_sub.latitude.size\n",
        "n_lon = u_sub.longitude.size\n",
        "\n",
        "labels_3d = labels.reshape(n_time, n_lat, n_lon)  # (time, lat, lon)\n",
        "dominant_cluster = mode(labels_3d, axis=0, nan_policy='omit').mode\n",
        "dominant_cluster = np.squeeze(dominant_cluster)  # shape: (lat, lon)\n",
        "\n",
        "# Step 8: Plot dominant cluster map\n",
        "lat = u_sub.latitude.values\n",
        "lon = u_sub.longitude.values\n",
        "lon2d, lat2d = np.meshgrid(lon, lat)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.BORDERS)\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "cf = ax.pcolormesh(lon2d, lat2d, dominant_cluster, cmap='tab10', shading='auto')\n",
        "plt.colorbar(cf, label=\"Cluster ID\")\n",
        "plt.title(\"ðŸŒ€ Dominant Wind Cluster per Grid Cell (2015â€“2025)\")\n",
        "plt.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/wind_cluster_map.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUpNcqeIBZv0"
      },
      "outputs": [],
      "source": [
        "!pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhIgFPIXr_l_"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from haversine import haversine, Unit\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load data (already merged all .nc files earlier)\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine='by_coords')\n",
        "\n",
        "# Select wind components\n",
        "u = ds['u'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "v = ds['v'].sel(pressure_level=850, latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Estimate area of one grid cell\n",
        "def estimate_grid_area(lat1, lat2, lon1, lon2):\n",
        "    p1 = (lat1, lon1)\n",
        "    p2 = (lat2, lon1)\n",
        "    p3 = (lat1, lon2)\n",
        "    width = haversine(p1, p3, unit=Unit.KILOMETERS)\n",
        "    height = haversine(p1, p2, unit=Unit.KILOMETERS)\n",
        "    return width * height\n",
        "\n",
        "grid_area = estimate_grid_area(\n",
        "    float(u.latitude[0]), float(u.latitude[1]),\n",
        "    float(u.longitude[0]), float(u.longitude[1])\n",
        ")\n",
        "\n",
        "# Time variable\n",
        "time = ds['valid_time'].values\n",
        "\n",
        "# Thresholds\n",
        "thresholds = [20, 30, 40, 50]\n",
        "area_data = {thresh: [] for thresh in thresholds}\n",
        "\n",
        "# Precompute speed in knots (shape: time x lat x lon)\n",
        "speed_knots_all = (np.sqrt(u**2 + v**2) * 1.94384).compute()\n",
        "\n",
        "# Loop over time\n",
        "for i in range(speed_knots_all.shape[0]):\n",
        "    speed_frame = speed_knots_all[i]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        mask = speed_frame > thresh\n",
        "        cell_count = mask.sum().item()  # âœ… Now safe, it's NumPy not Dask\n",
        "        area_km2 = cell_count * grid_area\n",
        "        area_data[thresh].append(area_km2)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_area = pd.DataFrame(area_data)\n",
        "df_area['date'] = pd.to_datetime(time)\n",
        "df_area.set_index('date', inplace=True)\n",
        "\n",
        "# ðŸ“ˆ Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "for thresh in thresholds:\n",
        "    plt.plot(df_area.index, df_area[thresh], label=f\"{thresh}+ knots\")\n",
        "\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Area (kmÂ²)\")\n",
        "plt.title(\"ðŸŒªï¸ Wind Area Coverage (Above Speed Thresholds)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/wind_speed_area_graph.png\", dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTNuLjfaBAKl"
      },
      "outputs": [],
      "source": [
        "'''ðŸ”¹ Pick one specific date (e.g., '2017-06-15')\n",
        "ðŸ”¹ Select only grid points where wind speed > 20 knots\n",
        "ðŸ”¹ Perform clustering (KMeans) only on that data\n",
        "ðŸ”¹ Plot the cluster map for that da '''\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load all NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select target date\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(valid_time=target_date, pressure_level=850,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "u = ds_day['u']\n",
        "v = ds_day['v']\n",
        "\n",
        "# Step 3: Subsample to reduce size\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "\n",
        "# Step 4: Compute wind speed in knots and mask by > 20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384  # m/s to knots\n",
        "mask = speed_knots > 20\n",
        "\n",
        "# Step 5: Flatten and filter valid wind vectors\n",
        "u_flat = u_sub.values[mask]\n",
        "v_flat = v_sub.values[mask]\n",
        "\n",
        "X = np.column_stack([u_flat, v_flat])  # shape (n_samples, 2)\n",
        "\n",
        "# Step 6: Cluster (if enough points)\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough points with > 20 knots wind on\", target_date)\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    # Step 7: Plot the clusters\n",
        "    print(f\"âœ… Clustering done for {len(X)} points on {target_date}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.quiver([0]*len(X), [0]*len(X), X[:, 0], X[:, 1], angles='xy', scale_units='xy', scale=1,\n",
        "               color=[['r', 'g', 'b'][l] for l in labels])\n",
        "    plt.quiver([0]*3, [0]*3, centroids[:, 0], centroids[:, 1], color='k', scale=1.5, width=0.01)\n",
        "    plt.xlim(-30, 30)\n",
        "    plt.ylim(-30, 30)\n",
        "    plt.grid()\n",
        "    plt.title(f\"ðŸ’¨ Wind Clusters on {target_date} (>20 knots)\")\n",
        "    plt.xlabel(\"U-component (m/s)\")\n",
        "    plt.ylabel(\"V-component (m/s)\")\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtFkw9QWfhYf"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>20 knots) on a map for one specific date - 850 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=850,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 20\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 20 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>20 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99SIKbmk4GFl"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>30 knots) on a map for one specific date - 850 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=850,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 20 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko59iXzW5DLL"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>40 knots) on a map for one specific date - 850 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=850,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 40\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 40 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>40 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEslMSb6iYPf"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>20 knots) on a map for one specific date - 925 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=925,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 20\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 20 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>20 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A_BNJy-59ej"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>30 knots) on a map for one specific date - 925 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=925,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 30 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9EEmDJ6IrW"
      },
      "outputs": [],
      "source": [
        "#Plot Wind Clusters (>40 knots) on a map for one specific date - 925 pressure level\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(pressure_level=925,\n",
        "                latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >20 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 40\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "# Remove the time dimension to make them 2D\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values  # shape: (lat, lon)\n",
        "\n",
        "# Apply mask properly\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "\n",
        "# Step 6: Run KMeans\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 20 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction per Cluster:\")\n",
        "\n",
        "    for i in range(3):  # or change to `range(kmeans.n_clusters)` if general\n",
        "    # Get all u and v values for this cluster\n",
        "       u_cluster = u_masked[labels == i]\n",
        "       v_cluster = v_masked[labels == i]\n",
        "\n",
        "    # Compute mean U and V components\n",
        "       u_mean = np.mean(u_cluster)\n",
        "       v_mean = np.mean(v_cluster)\n",
        "\n",
        "    # Compute average speed (magnitude)\n",
        "       speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "\n",
        "       # Compute average direction in degrees (0Â° = North, 90Â° = East)\n",
        "       direction_rad = np.arctan2(u_mean, v_mean)  # note: u is x, v is y\n",
        "       direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "       print(f\"ðŸŒ€ Cluster {i+1}:\")\n",
        "       print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "       print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    for i in range(3):\n",
        "        idx = (labels == i)\n",
        "        ax.quiver(lon_vals[idx], lat_vals[idx], u_masked[idx], v_masked[idx],\n",
        "                  color=colors[i], scale=400, width=0.002, transform=ccrs.PlateCarree(),\n",
        "                  label=f'Cluster {i+1}')\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Clusters on {target_date} (>40 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR8dbiTi2ADg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zJtFJDf1_Hg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Set the correct path\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"  # <-- update this\n",
        "\n",
        "# Check\n",
        "if os.path.exists(folder_path):\n",
        "    print(\"âœ… Folder exists:\", folder_path)\n",
        "    print(\"ðŸ“‚ Files in folder:\", os.listdir(folder_path))\n",
        "    print(\"ðŸ” .nc files found:\", glob.glob(os.path.join(folder_path, \"*.nc\")))\n",
        "else:\n",
        "    print(\"âŒ Folder not found:\", folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af_amJRz38CM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "from cartopy import feature as cfeature\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "# Extract full lat/lon arrays\n",
        "lat = ds_day.latitude.values\n",
        "lon = ds_day.longitude.values\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >30 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "\n",
        "# Remove the time dimension\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values\n",
        "\n",
        "# Mask points >30 knots\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Step 5b: Remove points over land\n",
        "# We'll use Cartopy's LAND geometry to exclude land points\n",
        "\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "# Function to test if a point is on land\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Apply land mask\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Keep only sea points\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Step 6: Run KMeans (only 1 cluster)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points over sea with wind > 30 knots on this date.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction for Sea Region:\")\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(f\"ðŸŒ€ Cluster:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Plot on map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    # Plot vectors\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors over Sea on {target_date} (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayFn40z2OY8w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import DBSCAN\n",
        "from shapely.geometry import Point\n",
        "from cartopy import feature as cfeature\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Find index of target date\n",
        "time_index = np.where(ds_day['valid_time'].dt.strftime('%Y-%m-%d') == target_date)[0][0]\n",
        "\n",
        "# Select single time slice\n",
        "u = ds_day['u'].isel(valid_time=time_index)\n",
        "v = ds_day['v'].isel(valid_time=time_index)\n",
        "\n",
        "# Extract lat/lon arrays\n",
        "lat = ds_day.latitude.values\n",
        "lon = ds_day.longitude.values\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute wind speed in knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare masked vectors and coordinates\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values\n",
        "\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Step 5b: Remove points over land\n",
        "# Use cartopy land geometries\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geom in land_geom.geometries():\n",
        "        if geom.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Check each point\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Keep only sea points\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Step 6: Run DBSCAN\n",
        "# We'll cluster wind vectors [u, v]\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "\n",
        "if len(X) < 5:\n",
        "    print(\"â— Not enough ocean points with wind > 30 knots on this date.\")\n",
        "else:\n",
        "    dbscan = DBSCAN(eps=2.5, min_samples=5).fit(X)\n",
        "    labels = dbscan.labels_\n",
        "\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    print(f\"âœ… Found {n_clusters} clusters over sea.\")\n",
        "\n",
        "    # Step 7: Print cluster summaries\n",
        "    for cluster_id in range(n_clusters):\n",
        "        idx = labels == cluster_id\n",
        "        u_cluster = u_masked[idx]\n",
        "        v_cluster = v_masked[idx]\n",
        "        avg_u = np.mean(u_cluster)\n",
        "        avg_v = np.mean(v_cluster)\n",
        "        speed_mean = np.sqrt(avg_u**2 + avg_v**2)\n",
        "        direction_rad = np.arctan2(avg_u, avg_v)\n",
        "        direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "        print(f\"ðŸŒ€ Cluster {cluster_id+1}:\")\n",
        "        print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "        print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 8: Plot clusters on a map\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    colors = plt.cm.get_cmap('tab10', n_clusters)\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "        idx = labels == i\n",
        "        ax.quiver(\n",
        "            lon_vals[idx], lat_vals[idx],\n",
        "            u_masked[idx], v_masked[idx],\n",
        "            color=colors(i),\n",
        "            scale=400, width=0.002,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            label=f\"Cluster {i+1}\"\n",
        "        )\n",
        "\n",
        "    # Plot noise points (optional)\n",
        "    if np.any(labels == -1):\n",
        "        idx = labels == -1\n",
        "        ax.quiver(\n",
        "            lon_vals[idx], lat_vals[idx],\n",
        "            u_masked[idx], v_masked[idx],\n",
        "            color='gray',\n",
        "            scale=400, width=0.002,\n",
        "            transform=ccrs.PlateCarree(),\n",
        "            label='Noise'\n",
        "        )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ DBSCAN Wind Clusters over Sea on {target_date} (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/dbscan_wind_cluster_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHluOcv_pgU7"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWzfv1Jc2YxN"
      },
      "outputs": [],
      "source": [
        "# 3 utc at >30 knots\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "from cartopy import feature as cfeature\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Filter valid_time at 03:00 UTC\n",
        "import pandas as pd\n",
        "target_datetime = pd.to_datetime(target_date + \" 03:00:00\")\n",
        "ds_day_3utc = ds_day.sel(valid_time=target_datetime, method=\"nearest\")\n",
        "\n",
        "# Select u, v\n",
        "u = ds_day_3utc['u']\n",
        "v = ds_day_3utc['v']\n",
        "\n",
        "# Extract full lat/lon arrays\n",
        "lat = ds_day.latitude.values\n",
        "lon = ds_day.longitude.values\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >30 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values\n",
        "\n",
        "# Mask points >30 knots\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Step 5b: Remove points over land\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Keep only sea points\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Step 6: KMeans Clustering (optional â€“ only 1 cluster here)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points over sea with wind > 30 knots at 3 UTC.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "\n",
        "    # Wind statistics\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction for Sea Region at 3 UTC:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Calculate area\n",
        "    # Approx area per grid cell (0.25Â° x 0.25Â°) ~ 770 kmÂ² (rough avg near equator)\n",
        "    area_per_cell_km2 = 770\n",
        "    sea_cell_count = len(lat_vals)\n",
        "    total_area_km2 = sea_cell_count * area_per_cell_km2\n",
        "    print(f\"ðŸŒŠ Total Sea Area with Wind > 30 knots at 3 UTC: {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "    # Step 8: Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster >30kt'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors at 850 hPa on {target_date} at 3 UTC (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}_3UTC.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2RMaDnbpMYJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "from cartopy import feature as cfeature\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and region\n",
        "target_date = \"2017-06-15\"\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Filter valid_time at 03:00 UTC\n",
        "import pandas as pd\n",
        "target_datetime = pd.to_datetime(target_date + \" 03:00:00\")\n",
        "ds_day_3utc = ds_day.sel(valid_time=target_datetime, method=\"nearest\")\n",
        "\n",
        "# Select u, v\n",
        "u = ds_day_3utc['u']\n",
        "v = ds_day_3utc['v']\n",
        "\n",
        "# Extract full lat/lon arrays\n",
        "lat = ds_day.latitude.values\n",
        "lon = ds_day.longitude.values\n",
        "\n",
        "# Step 3: Subsample (every 5th point)\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute speed in knots and mask by >30 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 20\n",
        "\n",
        "# Step 5: Prepare coordinates and vectors\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values\n",
        "\n",
        "# Mask points >30 knots\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Step 5b: Remove points over land\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Keep only sea points\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Step 6: KMeans Clustering (optional â€“ only 1 cluster here)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points over sea with wind > 20 knots at 3 UTC.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "\n",
        "    # Wind statistics\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction for Sea Region at 3 UTC:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Step 7: Calculate area\n",
        "    # Approx area per grid cell (0.25Â° x 0.25Â°) ~ 770 kmÂ² (rough avg near equator)\n",
        "    area_per_cell_km2 = 770\n",
        "    sea_cell_count = len(lat_vals)\n",
        "    total_area_km2 = sea_cell_count * area_per_cell_km2\n",
        "    print(f\"ðŸŒŠ Total Sea Area with Wind > 20 knots at 3 UTC: {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "    # Step 8: Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster >30kt'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors at 850 hPa on {target_date} at 3 UTC (>20 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_cluster_map_{target_date}_3UTC.png\", dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zef1j72f-pz7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and 12 UTC time\n",
        "target_date = \"2017-06-15\"\n",
        "target_datetime = pd.to_datetime(target_date + \" 12:00:00\")\n",
        "\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Use nearest time to 12 UTC\n",
        "ds_12utc = ds_day.sel(valid_time=target_datetime, method=\"nearest\")\n",
        "\n",
        "# Extract u, v components\n",
        "u = ds_12utc['u']\n",
        "v = ds_12utc['v']\n",
        "\n",
        "# Extract lat/lon\n",
        "lat = ds_12utc.latitude.values\n",
        "lon = ds_12utc.longitude.values\n",
        "\n",
        "# Subsample every 5th point\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Calculate speed in knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 20\n",
        "\n",
        "# Prepare meshgrid\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "\n",
        "# Apply mask\n",
        "u_vals = u_sub.values\n",
        "v_vals = v_sub.values\n",
        "mask2d = mask.values\n",
        "\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Remove land points using Cartopy geometries\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Filter to sea only\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Area Calculation: Estimate grid cell area (approximate)\n",
        "lat_resolution = abs(lat_sub[1] - lat_sub[0])\n",
        "lon_resolution = abs(lon_sub[1] - lon_sub[0])\n",
        "earth_radius_km = 6371\n",
        "\n",
        "# Approximate cell area in kmÂ² using spherical geometry\n",
        "cell_area_km2 = (111 * lat_resolution) * (111 * lon_resolution * np.cos(np.radians(lat_vals))).mean()\n",
        "total_area_km2 = len(lat_vals) * cell_area_km2\n",
        "\n",
        "# Print area\n",
        "print(f\"ðŸ“ Estimated Area Covered by Wind >20 knots over Sea (at 12 UTC): {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "# Step 6: Run KMeans (1 cluster for now)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind >20 knots.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸŒ€ Cluster Info (Sea, >20 knots):\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors over Sea on {target_date} 12 UTC (>20 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_12UTC_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FDOSZbTBbXe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOVgOxqlEjHh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and 12 UTC time\n",
        "target_date = \"2017-06-15\"\n",
        "target_datetime = pd.to_datetime(target_date + \" 12:00:00\")\n",
        "\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Use nearest time to 12 UTC\n",
        "ds_12utc = ds_day.sel(valid_time=target_datetime, method=\"nearest\")\n",
        "\n",
        "# Extract u, v components\n",
        "u = ds_12utc['u']\n",
        "v = ds_12utc['v']\n",
        "\n",
        "# Extract lat/lon\n",
        "lat = ds_12utc.latitude.values\n",
        "lon = ds_12utc.longitude.values\n",
        "\n",
        "# Subsample every 5th point\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Calculate speed in knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Prepare meshgrid\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "\n",
        "# Apply mask\n",
        "u_vals = u_sub.values\n",
        "v_vals = v_sub.values\n",
        "mask2d = mask.values\n",
        "\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Remove land points using Cartopy geometries\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Filter to sea only\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Area Calculation: Estimate grid cell area (approximate)\n",
        "lat_resolution = abs(lat_sub[1] - lat_sub[0])\n",
        "lon_resolution = abs(lon_sub[1] - lon_sub[0])\n",
        "earth_radius_km = 6371\n",
        "\n",
        "# Approximate cell area in kmÂ² using spherical geometry\n",
        "cell_area_km2 = (111 * lat_resolution) * (111 * lon_resolution * np.cos(np.radians(lat_vals))).mean()\n",
        "total_area_km2 = len(lat_vals) * cell_area_km2\n",
        "\n",
        "# Print area\n",
        "print(f\"ðŸ“ Estimated Area Covered by Wind >20 knots over Sea (at 12 UTC): {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "# Step 6: Run KMeans (1 cluster for now)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind >30 knots.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸŒ€ Cluster Info (Sea, >30 knots):\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors over Sea on {target_date} 12 UTC (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_12UTC_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiZalYLtE7Ko"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load NetCDF files\n",
        "folder_path = \"/content/drive/MyDrive/wind_data\"\n",
        "nc_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")])\n",
        "ds = xr.open_mfdataset(nc_files, combine=\"by_coords\")\n",
        "\n",
        "# Step 2: Select one date and 12 UTC time\n",
        "target_date = \"2017-06-15\"\n",
        "target_datetime = pd.to_datetime(target_date + \" 12:00:00\")\n",
        "\n",
        "ds_day = ds.sel(\n",
        "    pressure_level=850,\n",
        "    latitude=slice(30, -15),\n",
        "    longitude=slice(30, 75)\n",
        ")\n",
        "\n",
        "# Use nearest time to 12 UTC\n",
        "ds_12utc = ds_day.sel(valid_time=target_datetime, method=\"nearest\")\n",
        "\n",
        "# Extract u, v components\n",
        "u = ds_12utc['u']\n",
        "v = ds_12utc['v']\n",
        "\n",
        "# Extract lat/lon\n",
        "lat = ds_12utc.latitude.values\n",
        "lon = ds_12utc.longitude.values\n",
        "\n",
        "# Subsample every 5th point\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Calculate speed in knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 40\n",
        "\n",
        "# Prepare meshgrid\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "\n",
        "# Apply mask\n",
        "u_vals = u_sub.values\n",
        "v_vals = v_sub.values\n",
        "mask2d = mask.values\n",
        "\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Remove land points using Cartopy geometries\n",
        "land_geom = cfeature.NaturalEarthFeature('physical', 'land', '50m')\n",
        "\n",
        "def is_land(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for geometry in land_geom.geometries():\n",
        "        if geometry.contains(point):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "is_sea = np.array([not is_land(lat, lon) for lat, lon in zip(lat_vals, lon_vals)])\n",
        "\n",
        "# Filter to sea only\n",
        "lat_vals = lat_vals[is_sea]\n",
        "lon_vals = lon_vals[is_sea]\n",
        "u_masked = u_masked[is_sea]\n",
        "v_masked = v_masked[is_sea]\n",
        "\n",
        "# Area Calculation: Estimate grid cell area (approximate)\n",
        "lat_resolution = abs(lat_sub[1] - lat_sub[0])\n",
        "lon_resolution = abs(lon_sub[1] - lon_sub[0])\n",
        "earth_radius_km = 6371\n",
        "\n",
        "# Approximate cell area in kmÂ² using spherical geometry\n",
        "cell_area_km2 = (111 * lat_resolution) * (111 * lon_resolution * np.cos(np.radians(lat_vals))).mean()\n",
        "total_area_km2 = len(lat_vals) * cell_area_km2\n",
        "\n",
        "# Print area\n",
        "print(f\"ðŸ“ Estimated Area Covered by Wind >40 knots over Sea (at 12 UTC): {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "# Step 6: Run KMeans (1 cluster for now)\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind >40 knots.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸŒ€ Cluster Info (Sea, >40 knots):\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    # Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='Sea Cluster'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors over Sea on {target_date} 12 UTC (>40 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/wind_12UTC_{target_date}.png\", dpi=300)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmfQLtCh7Gdc"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from sklearn.cluster import KMeans\n",
        "from shapely.geometry import Point\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the uploaded NetCDF file\n",
        "file_path = \"51a782427669b5c095dc96623e79a5ae.nc.nc\"\n",
        "ds = xr.open_dataset(file_path)\n",
        "\n",
        "# Print available times for reference\n",
        "print(\"Available times:\", ds.valid_time.values)\n",
        "\n",
        "# âœ… Use correct year and time from your dataset\n",
        "target_date = \"2015-06-21\"\n",
        "target_datetime = pd.to_datetime(target_date + \" 12:00:00\")\n",
        "\n",
        "# Step 1: Select nearest time FIRST\n",
        "ds_time = ds.sel(\n",
        "    valid_time=target_datetime,\n",
        "    method=\"nearest\"\n",
        ")\n",
        "\n",
        "# Step 2: Slice latitude and longitude\n",
        "ds_day = ds_time.sel(\n",
        "    latitude=slice(30, -15),   # southward slice\n",
        "    longitude=slice(30, 75)    # eastward slice\n",
        ")\n",
        "\n",
        "# âœ… Use the correct variable names in your dataset\n",
        "u = ds_day['u10']\n",
        "v = ds_day['v10']\n",
        "lat = ds_day.latitude.values\n",
        "lon = ds_day.longitude.values\n",
        "\n",
        "# Step 3: Subsample every 5th point\n",
        "u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "lat_sub = lat[::5]\n",
        "lon_sub = lon[::5]\n",
        "\n",
        "# Step 4: Compute wind speed in knots and mask >30 knots\n",
        "speed = np.sqrt(u_sub**2 + v_sub**2)\n",
        "speed_knots = speed * 1.94384\n",
        "mask = speed_knots > 30\n",
        "\n",
        "# Step 5: Prepare coordinates and mask values\n",
        "lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "u_vals = u_sub.squeeze().values\n",
        "v_vals = v_sub.squeeze().values\n",
        "mask2d = mask.squeeze().values\n",
        "\n",
        "lat_vals = lat2d[mask2d]\n",
        "lon_vals = lon2d[mask2d]\n",
        "u_masked = u_vals[mask2d]\n",
        "v_masked = v_vals[mask2d]\n",
        "\n",
        "# Step 6: Skip land filtering for speed (optional)\n",
        "# Step 7: KMeans clustering\n",
        "X = np.column_stack((u_masked, v_masked))\n",
        "if len(X) < 10:\n",
        "    print(\"â— Not enough data points with wind > 30 knots at 12 UTC.\")\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean = np.sqrt(u_mean**2 + v_mean**2)\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    print(\"ðŸ“ Average Speed and Direction at 12 UTC:\")\n",
        "    print(f\"   â–ª Mean Speed: {speed_mean:.2f} m/s\")\n",
        "    print(f\"   â–ª Mean Direction: {direction_deg:.2f}Â°\")\n",
        "\n",
        "    area_per_cell_km2 = 770\n",
        "    total_area_km2 = len(lat_vals) * area_per_cell_km2\n",
        "    print(f\"ðŸŒŠ Total Area with Wind > 30 knots at 12 UTC: {total_area_km2:.2f} kmÂ²\")\n",
        "\n",
        "    # Step 8: Plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_extent([30, 75, -15, 30], crs=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS)\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.OCEAN)\n",
        "\n",
        "    ax.quiver(\n",
        "        lon_vals, lat_vals,\n",
        "        u_masked, v_masked,\n",
        "        color='red', scale=400, width=0.002,\n",
        "        transform=ccrs.PlateCarree(),\n",
        "        label='>30kt Wind Vectors'\n",
        "    )\n",
        "\n",
        "    plt.title(f\"ðŸŒ€ Wind Vectors on {target_date} nearest 12 UTC (>30 knots)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2yb54QjkvMYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iske baad mera kaam h -Arshleen**"
      ],
      "metadata": {
        "id": "sVYvolg-vrvg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDiw_G0NFIVo"
      },
      "outputs": [],
      "source": [
        "# Do this for every year and combine the files\n",
        "!pip install netCDF4 xarray tqdm\n",
        "\n",
        "# ðŸ“ Upload the .nc file from local storage\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# ðŸ“‚ Load uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "ds = xr.open_dataset(filename, engine=\"netcdf4\")\n",
        "\n",
        "# Extract all available times\n",
        "times = pd.to_datetime(ds.valid_time.values)\n",
        "dates = sorted(set([t.date() for t in times]))\n",
        "\n",
        "# âœ… Filter by year\n",
        "target_year = 2007\n",
        "dates = [d for d in dates if d.year == target_year]\n",
        "\n",
        "# Define thresholds in knots\n",
        "thresholds = [20, 30, 40]\n",
        "\n",
        "# Initialize result containers\n",
        "data_3utc = {thr: [] for thr in thresholds}\n",
        "data_12utc = {thr: [] for thr in thresholds}\n",
        "\n",
        "# ðŸ“Š Function to compute wind stats\n",
        "def compute_stats(ds_slice, threshold_knots):\n",
        "    if 'u' not in ds_slice or 'v' not in ds_slice:\n",
        "        raise KeyError(\"âŒ Variables 'u' or 'v' not found in dataset.\")\n",
        "\n",
        "    pressure_level = 850  # Update if necessary\n",
        "    u = ds_slice['u'].sel(pressure_level=pressure_level)\n",
        "    v = ds_slice['v'].sel(pressure_level=pressure_level)\n",
        "\n",
        "    lat = ds_slice.latitude.values\n",
        "    lon = ds_slice.longitude.values\n",
        "\n",
        "    u_sub = u.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "    v_sub = v.isel(latitude=slice(0, None, 5), longitude=slice(0, None, 5))\n",
        "    lat_sub = lat[::5]\n",
        "    lon_sub = lon[::5]\n",
        "\n",
        "    speed = np.sqrt(u_sub ** 2 + v_sub ** 2)\n",
        "    speed_knots = speed * 1.94384\n",
        "\n",
        "    mask = speed_knots > threshold_knots\n",
        "\n",
        "    lat2d, lon2d = np.meshgrid(lat_sub, lon_sub, indexing='ij')\n",
        "    u_vals = u_sub.squeeze().values\n",
        "    v_vals = v_sub.squeeze().values\n",
        "    mask2d = mask.squeeze().values\n",
        "\n",
        "    u_masked = u_vals[mask2d]\n",
        "    v_masked = v_vals[mask2d]\n",
        "    lat_vals = lat2d[mask2d]\n",
        "\n",
        "    if len(u_masked) < 5:\n",
        "        return None\n",
        "\n",
        "    u_mean = np.mean(u_masked)\n",
        "    v_mean = np.mean(v_masked)\n",
        "    speed_mean_mps = np.sqrt(u_mean ** 2 + v_mean ** 2)\n",
        "    speed_mean_knots = speed_mean_mps * 1.94384\n",
        "\n",
        "    direction_rad = np.arctan2(u_mean, v_mean)\n",
        "    direction_deg = (np.degrees(direction_rad) + 360) % 360\n",
        "\n",
        "    area_deg2 = len(lat_vals) * (5 * 5)\n",
        "    return speed_mean_knots, direction_deg, area_deg2\n",
        "\n",
        "# ðŸ•’ Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# ðŸ” Loop through dates\n",
        "for i, date in enumerate(tqdm(dates, desc=f\"Processing {target_year}\")):\n",
        "    for utc_hour, store_dict in [(3, data_3utc), (12, data_12utc)]:\n",
        "        target_dt = pd.to_datetime(f\"{date} {utc_hour:02d}:00:00\")\n",
        "        if target_dt not in times:\n",
        "            continue\n",
        "\n",
        "        ds_time = ds.sel(valid_time=target_dt, method=\"nearest\")\n",
        "        ds_day = ds_time.sel(latitude=slice(30, -15), longitude=slice(30, 75))\n",
        "\n",
        "        for thr in thresholds:\n",
        "            stats = compute_stats(ds_day, thr)\n",
        "            if stats:\n",
        "                speed_mean_knots, direction_deg, area_deg2 = stats\n",
        "                store_dict[thr].append({\n",
        "                    \"Date\": date,\n",
        "                    \"UTC_Hour\": utc_hour,\n",
        "                    \"Threshold_knots\": thr,\n",
        "                    \"Mean_Speed_knots\": speed_mean_knots,\n",
        "                    \"Mean_Direction_deg\": direction_deg,\n",
        "                    \"Area_deg2\": area_deg2\n",
        "                })\n",
        "\n",
        "    # ðŸ’¾ Save partial every 100 days\n",
        "    if (i + 1) % 100 == 0:\n",
        "        temp_dfs = []\n",
        "        for hour_label, data_dict in [(\"3UTC\", data_3utc), (\"12UTC\", data_12utc)]:\n",
        "            for thr, records in data_dict.items():\n",
        "                if records:\n",
        "                    df = pd.DataFrame(records)\n",
        "                    df[\"UTC_Label\"] = hour_label\n",
        "                    temp_dfs.append(df)\n",
        "        if temp_dfs:\n",
        "            partial_df = pd.concat(temp_dfs, ignore_index=True)\n",
        "            partial_filename = f\"wind_partial_{target_year}_day{i+1}.csv\"\n",
        "            partial_df.to_csv(partial_filename, index=False)\n",
        "            print(f\"ðŸ’¾ Saved partial: {partial_filename}\")\n",
        "\n",
        "# âœ… Final save\n",
        "dfs = []\n",
        "for hour_label, data_dict in [(\"3UTC\", data_3utc), (\"12UTC\", data_12utc)]:\n",
        "    for thr, records in data_dict.items():\n",
        "        if records:\n",
        "            df = pd.DataFrame(records)\n",
        "            df[\"UTC_Label\"] = hour_label\n",
        "            dfs.append(df)\n",
        "\n",
        "if dfs:\n",
        "    final_df = pd.concat(dfs, ignore_index=True)\n",
        "    output_csv = f\"wind_analysis_{target_year}.csv\"\n",
        "    final_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\nâœ… Final saved: {output_csv}\")\n",
        "\n",
        "    # ðŸ“ˆ Print averages\n",
        "    for thr in thresholds:\n",
        "        for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "            sub = final_df[(final_df[\"Threshold_knots\"] == thr) &\n",
        "                           (final_df[\"UTC_Label\"] == utc_label)]\n",
        "            if not sub.empty:\n",
        "                print(f\"\\nðŸŒŸ {utc_label} | Threshold {thr} knots:\")\n",
        "                print(f\"â–ª Mean Speed: {sub['Mean_Speed_knots'].mean():.2f} knots\")\n",
        "                print(f\"â–ª Mean Direction: {sub['Mean_Direction_deg'].mean():.2f}Â°\")\n",
        "                print(f\"â–ª Mean Area: {sub['Area_deg2'].mean():.2f} degÂ²\")\n",
        "else:\n",
        "    print(\"âš ï¸ No data found.\")\n",
        "\n",
        "# â±ï¸ Runtime\n",
        "end_time = time.time()\n",
        "print(f\"\\nâ±ï¸ Total runtime: {round((end_time - start_time) / 60, 2)} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qgD2-AK4sXi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Combine yearly CSVs into one\n",
        "combined_df = pd.concat([pd.read_csv(f\"wind_analysis_{y}.csv\") for y in range(1992, 2024)])\n",
        "combined_df.to_csv(\"(1992-2024)\", index=False)\n",
        "\n",
        "print(\"âœ… Combined file saved as '(1992-2024).csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUls2kSX4_tq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do1MfYhN8r8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "faWx_NqeesGw"
      },
      "outputs": [],
      "source": [
        "#plots the graphs\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the file is named (1992-2014).csv\n",
        "input_csv = \"(1992-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "print(\"ðŸ“Š DataFrame shape:\", df.shape)\n",
        "print(\"ðŸ§¾ Columns:\", df.columns)\n",
        "\n",
        "# Thresholds to plot\n",
        "thresholds = [20, 30, 40]\n",
        "\n",
        "# Plot area over time\n",
        "for thr in thresholds:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "        sub = df[(df[\"Threshold_knots\"] == thr) &\n",
        "                 (df[\"UTC_Label\"] == utc_label)]\n",
        "        if not sub.empty:\n",
        "            sub_sorted = sub.sort_values(\"Date\")\n",
        "            plt.plot(sub_sorted[\"Date\"], sub_sorted[\"Area_deg2\"],\n",
        "                     label=f\"{utc_label}\", marker='o', linestyle='-')\n",
        "    plt.title(f\"Area Above {thr} knots Over Time (1992â€“2014)\")\n",
        "    plt.ylabel(\"Area (degÂ²)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot mean wind direction over time\n",
        "for thr in thresholds:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "        sub = df[(df[\"Threshold_knots\"] == thr) &\n",
        "                 (df[\"UTC_Label\"] == utc_label)]\n",
        "        if not sub.empty:\n",
        "            sub_sorted = sub.sort_values(\"Date\")\n",
        "            plt.plot(sub_sorted[\"Date\"], sub_sorted[\"Mean_Direction_deg\"],\n",
        "                     label=f\"{utc_label}\", marker='x', linestyle='-')\n",
        "    plt.title(f\"Mean Wind Direction Above {thr} knots Over Time (1992â€“2014)\")\n",
        "    plt.ylabel(\"Mean Direction (degrees)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Print overall averages\n",
        "for thr in thresholds:\n",
        "    for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "        sub = df[\n",
        "            (df[\"Threshold_knots\"] == thr) &\n",
        "            (df[\"UTC_Label\"] == utc_label)\n",
        "        ]\n",
        "        if not sub.empty:\n",
        "            mean_speed_knots = sub[\"Mean_Speed_knots\"].mean()\n",
        "            mean_dir = sub[\"Mean_Direction_deg\"].mean()\n",
        "            mean_area = sub[\"Area_deg2\"].mean()\n",
        "            print(f\"\\nðŸŒŸ {utc_label} | Threshold {thr} knots:\")\n",
        "            print(f\"â–ª Mean Speed: {mean_speed_knots:.2f} knots\")\n",
        "            print(f\"â–ª Mean Direction: {mean_dir:.2f}Â°\")\n",
        "            print(f\"â–ª Mean Area: {mean_area:.2f} degÂ²\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GLvUVueVfDLy"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the CSV file\n",
        "input_csv = \"(1992-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "print(\"ðŸ“Š DataFrame shape:\", df.shape)\n",
        "print(\"ðŸ§¾ Columns:\", df.columns)\n",
        "\n",
        "# Filter for threshold 20 knots\n",
        "thr = 20\n",
        "df = df[df[\"Threshold_knots\"] == thr]\n",
        "\n",
        "# Add 'Year' column for grouping\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "years = sorted(df[\"Year\"].unique())\n",
        "\n",
        "# Plot area over time for each year\n",
        "for year in years:\n",
        "    df_year = df[df[\"Year\"] == year]\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "        sub = df_year[df_year[\"UTC_Label\"] == utc_label].sort_values(\"Date\")\n",
        "        if not sub.empty:\n",
        "            plt.plot(sub[\"Date\"], sub[\"Area_deg2\"],\n",
        "                     label=f\"{utc_label}\", marker='o', linestyle='-')\n",
        "    plt.title(f\"[{year}] Area Above 20 knots\")\n",
        "    plt.ylabel(\"Area (degÂ²)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot mean wind direction over time for each year\n",
        "for year in years:\n",
        "    df_year = df[df[\"Year\"] == year]\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for utc_label in [\"3UTC\", \"12UTC\"]:\n",
        "        sub = df_year[df_year[\"UTC_Label\"] == utc_label].sort_values(\"Date\")\n",
        "        if not sub.empty:\n",
        "            plt.plot(sub[\"Date\"], sub[\"Mean_Direction_deg\"],\n",
        "                     label=f\"{utc_label}\", marker='x', linestyle='-')\n",
        "    plt.title(f\"[{year}] Wind Direction Above 20 knots\")\n",
        "    plt.ylabel(\"Direction (Â°)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ZTAZPDgnWt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload CSV\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Read CSV\n",
        "df = pd.read_csv(file_name)\n",
        "print(\"âœ… CSV loaded:\", file_name)\n",
        "print(df.head())  # Show first few rows\n",
        "print(df.columns)  # Show column names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH1by1-ohrWo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert 'Date' column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Filter data for 2002 and 2003\n",
        "df_2002 = df[df['Date'].dt.year == 2002]\n",
        "df_2003 = df[df['Date'].dt.year == 2003]\n",
        "\n",
        "# Plot Area_deg2 over time\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(df_2002['Date'], df_2002['Area_deg2'], label='2002', color='blue', alpha=0.7)\n",
        "plt.plot(df_2003['Date'], df_2003['Area_deg2'], label='2003', color='red', alpha=0.7)\n",
        "\n",
        "plt.title(\"ðŸ“ˆ Area (degÂ²) above 20 knots â€” 2002 vs 2003\")\n",
        "plt.ylabel(\"Area (degÂ²)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9zyJiC-nWtOz"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load data\n",
        "input_csv = \"(1992-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "\n",
        "# Extract year and decade columns\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Decade\"] = (df[\"Year\"] // 10) * 10\n",
        "\n",
        "# Thresholds to analyze\n",
        "thresholds = [20, 30, 40]\n",
        "utc_labels = [\"3UTC\", \"12UTC\"]\n",
        "stats_cols = [\"Mean_Speed_knots\", \"Mean_Direction_deg\", \"Area_deg2\"]\n",
        "\n",
        "# Store statistics\n",
        "from collections import defaultdict\n",
        "stats_summary = defaultdict(dict)\n",
        "\n",
        "# === YEARLY AND DECADAL AGGREGATES + VARIANCES ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        # Yearly statistics\n",
        "        yearly_stats = subset.groupby(\"Year\")[stats_cols].agg([\"mean\", \"var\"])\n",
        "        print(f\"\\nðŸ“… YEARLY STATS for {thr} knots, {utc}\")\n",
        "        print(yearly_stats)\n",
        "\n",
        "        # Plot yearly changes\n",
        "        for col in stats_cols:\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(yearly_stats.index, yearly_stats[(col, \"mean\")], marker='o', label=\"Mean\")\n",
        "            plt.title(f\"{col} Yearly Mean - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(col)\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(yearly_stats.index, yearly_stats[(col, \"var\")], marker='x', label=\"Variance\", color='red')\n",
        "            plt.title(f\"{col} Yearly Variance - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(f\"Variance of {col}\")\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Decadal statistics\n",
        "        decadal_stats = subset.groupby(\"Decade\")[stats_cols].agg([\"mean\", \"var\"])\n",
        "        print(f\"\\nðŸ§® DECADAL STATS for {thr} knots, {utc}\")\n",
        "        print(decadal_stats)\n",
        "\n",
        "        # Plot decadal changes\n",
        "        for col in stats_cols:\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(decadal_stats.index, decadal_stats[(col, \"mean\")], marker='s', label=\"Mean\")\n",
        "            plt.title(f\"{col} Decadal Mean - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Decade\")\n",
        "            plt.ylabel(col)\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(decadal_stats.index, decadal_stats[(col, \"var\")], marker='^', color='purple', label=\"Variance\")\n",
        "            plt.title(f\"{col} Decadal Variance - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Decade\")\n",
        "            plt.ylabel(f\"Variance of {col}\")\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Overall variance for this threshold and UTC label\n",
        "        overall_variance = subset[stats_cols].var()\n",
        "        stats_summary[(thr, utc)][\"Overall Variance\"] = overall_variance\n",
        "\n",
        "# === OVERALL VARIANCE ACROSS FULL DATASET ===\n",
        "print(\"\\nðŸ“ˆ OVERALL VARIANCE (entire dataset per threshold and UTC):\")\n",
        "for key, val in stats_summary.items():\n",
        "    thr, utc = key\n",
        "    print(f\"\\nâš¡ {thr} knots | {utc}:\")\n",
        "    print(val[\"Overall Variance\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 0: Imports and Upload CSV ===\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.fft import fft, fftfreq\n",
        "from collections import defaultdict\n",
        "\n",
        "# Upload your CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# === Step 1: Load and Preprocess ===\n",
        "input_csv = \"(1963-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Decade\"] = (df[\"Year\"] // 10) * 10\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "\n",
        "# Filter JJAS months\n",
        "df_jjas = df[df[\"Month\"].isin([6, 7, 8, 9])]\n",
        "\n",
        "# Define thresholds and labels\n",
        "thresholds = [20, 30, 40]\n",
        "utc_labels = [\"3UTC\", \"12UTC\"]\n",
        "stats_cols = [\"Mean_Speed_knots\", \"Mean_Direction_deg\", \"Area_deg2\"]\n",
        "\n",
        "# Store summary\n",
        "stats_summary = defaultdict(dict)\n",
        "\n",
        "# === Step 2: Monthly and Seasonal Plots ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df_jjas[(df_jjas[\"Threshold_knots\"] == thr) & (df_jjas[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== {thr} knots | {utc} ===\")\n",
        "\n",
        "        # Monthly Averages\n",
        "        monthly_avg = subset.groupby(\"Month\")[stats_cols].mean()\n",
        "\n",
        "        # A. Monthly Wind Speed Variation (Bar Chart)\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(monthly_avg.index, monthly_avg[\"Mean_Speed_knots\"], color='skyblue', edgecolor='black')\n",
        "        plt.title(f\"Monthly Mean Wind Speed (JJAS) - {thr} knots {utc}\")\n",
        "        plt.xlabel(\"Month\")\n",
        "        plt.ylabel(\"Mean Wind Speed (knots)\")\n",
        "        plt.xticks([6, 7, 8, 9], [\"June\", \"July\", \"Aug\", \"Sept\"])\n",
        "        plt.grid(axis='y')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Regular monthly line plots\n",
        "        for col in stats_cols:\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(monthly_avg.index, monthly_avg[col], marker='o')\n",
        "            plt.title(f\"{col} Monthly Avg (JJAS) - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Month\")\n",
        "            plt.ylabel(col)\n",
        "            plt.xticks([6, 7, 8, 9], [\"June\", \"July\", \"Aug\", \"Sept\"])\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Seasonal Boxplots (per year)\n",
        "        for col in stats_cols:\n",
        "            season_data = subset.groupby(\"Year\")[col].apply(list).dropna()\n",
        "\n",
        "            plt.figure(figsize=(16, 6))  # Enlarged size\n",
        "            plt.boxplot(season_data,\n",
        "                        positions=season_data.index,\n",
        "                        widths=0.8,\n",
        "                        patch_artist=True,\n",
        "                        boxprops=dict(facecolor='lightblue'),\n",
        "                        medianprops=dict(color='red', linewidth=2),\n",
        "                        whiskerprops=dict(linewidth=1.5),\n",
        "                        capprops=dict(linewidth=1.5),\n",
        "                        flierprops=dict(marker='o', markersize=4, markerfacecolor='gray'))\n",
        "\n",
        "            plt.title(f\"Seasonal Boxplot of {col} (JJAS) - {thr} knots {utc}\", fontsize=14)\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(col)\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# === Step 3: Spectral (FFT) Analysis ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        for col in stats_cols:\n",
        "            yearly_mean = subset.groupby(\"Year\")[col].mean().dropna()\n",
        "            if yearly_mean.empty or len(yearly_mean) < 10:\n",
        "                continue\n",
        "\n",
        "            signal = yearly_mean.values\n",
        "            N = len(signal)\n",
        "            T = 1  # 1 year interval\n",
        "            freqs = fftfreq(N, T)\n",
        "            fft_vals = fft(signal)\n",
        "\n",
        "            power = np.abs(fft_vals[:N//2]) ** 2\n",
        "            freqs = freqs[:N//2]\n",
        "\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(freqs, power)\n",
        "            plt.title(f\"Power Spectrum of {col} - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Frequency (1/year)\")\n",
        "            plt.ylabel(\"Power\")\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Dominant Oscillation\n",
        "            dominant_freq = freqs[np.argmax(power)]\n",
        "            period = 1 / dominant_freq if dominant_freq != 0 else float('inf')\n",
        "            print(f\"ðŸ” Dominant Period for {col} ({thr} knots, {utc}): ~{period:.2f} years\")\n",
        "\n",
        "# === Step 4: Optional Overall Variance Report ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if not subset.empty:\n",
        "            stats_summary[(thr, utc)][\"Overall Variance\"] = subset[stats_cols].var()\n",
        "\n",
        "print(\"\\nðŸ“ˆ OVERALL VARIANCE (entire dataset per threshold and UTC):\")\n",
        "for key, val in stats_summary.items():\n",
        "    thr, utc = key\n",
        "    print(f\"\\nâš¡ {thr} knots | {utc}:\")\n",
        "    print(val[\"Overall Variance\"])\n"
      ],
      "metadata": {
        "id": "TU8hhgo--nnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgeZmrTn79x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 0: Imports and Upload CSV ===\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.fft import fft, fftfreq\n",
        "from collections import defaultdict\n",
        "\n",
        "# Upload your CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# === Step 1: Load and Preprocess ===\n",
        "input_csv = \"(1963-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Decade\"] = (df[\"Year\"] // 10) * 10\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "\n",
        "# Filter JJAS months\n",
        "df_jjas = df[df[\"Month\"].isin([6, 7, 8, 9])]\n",
        "\n",
        "# Define thresholds and labels\n",
        "thresholds = [20, 30, 40]\n",
        "utc_labels = [\"3UTC\", \"12UTC\"]\n",
        "stats_cols = [\"Mean_Speed_knots\", \"Mean_Direction_deg\", \"Area_deg2\"]\n",
        "\n",
        "# Store summary\n",
        "stats_summary = defaultdict(dict)\n",
        "\n",
        "# === Step 2: Monthly and Seasonal Plots ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df_jjas[(df_jjas[\"Threshold_knots\"] == thr) & (df_jjas[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== {thr} knots | {utc} ===\")\n",
        "\n",
        "        # Monthly Averages\n",
        "        monthly_avg = subset.groupby(\"Month\")[stats_cols].mean()\n",
        "\n",
        "        # A. Monthly Wind Speed Variation (Bar Chart)\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(monthly_avg.index, monthly_avg[\"Mean_Speed_knots\"], color='skyblue', edgecolor='black')\n",
        "        plt.title(f\"Monthly Mean Wind Speed (JJAS) - {thr} knots {utc}\")\n",
        "        plt.xlabel(\"Month\")\n",
        "        plt.ylabel(\"Mean Wind Speed (knots)\")\n",
        "        plt.xticks([6, 7, 8, 9], [\"June\", \"July\", \"Aug\", \"Sept\"])\n",
        "        plt.grid(axis='y')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Monthly Line Plots\n",
        "        for col in stats_cols:\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(monthly_avg.index, monthly_avg[col], marker='o')\n",
        "            plt.title(f\"{col} Monthly Avg (JJAS) - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Month\")\n",
        "            plt.ylabel(col)\n",
        "            plt.xticks([6, 7, 8, 9], [\"June\", \"July\", \"Aug\", \"Sept\"])\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Seasonal Boxplots with line graph + trend line\n",
        "        for col in stats_cols:\n",
        "            season_data = subset.groupby(\"Year\")[col].apply(list).dropna()\n",
        "            yearly_means = subset.groupby(\"Year\")[col].mean().dropna()\n",
        "            years = yearly_means.index\n",
        "            means = yearly_means.values\n",
        "\n",
        "            plt.figure(figsize=(16, 6))\n",
        "            # Boxplot\n",
        "            plt.boxplot(season_data,\n",
        "                        positions=season_data.index,\n",
        "                        widths=0.8,\n",
        "                        patch_artist=True,\n",
        "                        boxprops=dict(facecolor='lightblue'),\n",
        "                        medianprops=dict(color='red', linewidth=2),\n",
        "                        whiskerprops=dict(linewidth=1.5),\n",
        "                        capprops=dict(linewidth=1.5),\n",
        "                        flierprops=dict(marker='o', markersize=4, markerfacecolor='gray'))\n",
        "\n",
        "            # Line plot of means\n",
        "            plt.plot(years, means, color='black', marker='o', linestyle='-', label='Yearly Mean')\n",
        "\n",
        "            # Trend line\n",
        "            z = np.polyfit(years, means, 1)\n",
        "            p = np.poly1d(z)\n",
        "            plt.plot(years, p(years), color='darkblue', linewidth=2, linestyle='--', label='Trend')\n",
        "\n",
        "            plt.title(f\"{col} Seasonal Boxplot + Mean Line (JJAS) - {thr} knots {utc}\", fontsize=14)\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(col)\n",
        "            plt.legend()\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# === Step 3: Spectral (FFT) Analysis â€” Only Print Period ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        for col in stats_cols:\n",
        "            yearly_mean = subset.groupby(\"Year\")[col].mean().dropna()\n",
        "            if yearly_mean.empty or len(yearly_mean) < 10:\n",
        "                continue\n",
        "\n",
        "            signal = yearly_mean.values - np.mean(yearly_mean.values)\n",
        "            N = len(signal)\n",
        "            T = 1  # 1 year interval\n",
        "            freqs = fftfreq(N, T)\n",
        "            fft_vals = fft(signal)\n",
        "\n",
        "            power = np.abs(fft_vals[:N//2]) ** 2\n",
        "            freqs = freqs[:N//2]\n",
        "\n",
        "            nonzero_freqs = freqs[freqs > 0]\n",
        "            nonzero_power = power[freqs > 0]\n",
        "            if len(nonzero_freqs) > 0:\n",
        "                dominant_freq = nonzero_freqs[np.argmax(nonzero_power)]\n",
        "                period = 1 / dominant_freq\n",
        "            else:\n",
        "                period = float('inf')\n",
        "\n",
        "            print(f\"ðŸ” Dominant Period for {col} ({thr} knots, {utc}): ~{period:.2f} years\")\n",
        "\n",
        "# === Step 4: Overall Variance Report ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if not subset.empty:\n",
        "            stats_summary[(thr, utc)][\"Overall Variance\"] = subset[stats_cols].var()\n",
        "\n",
        "print(\"\\nðŸ“ˆ OVERALL VARIANCE (entire dataset per threshold and UTC):\")\n",
        "for key, val in stats_summary.items():\n",
        "    thr, utc = key\n",
        "    print(f\"\\nâš¡ {thr} knots | {utc}:\")\n",
        "    print(val[\"Overall Variance\"])\n"
      ],
      "metadata": {
        "id": "RTT-QzR5BB2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 0: Imports and Upload CSV ===\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.fft import fft, fftfreq\n",
        "\n",
        "# === Upload CSV File ===\n",
        "uploaded = files.upload()\n",
        "input_csv = \"(1963-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "\n",
        "# === Step 1: Preprocess ===\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "df[\"Day\"] = df[\"Date\"].dt.dayofyear  # For daily grouping\n",
        "\n",
        "# Filter JJAS months\n",
        "df_jjas = df[df[\"Month\"].isin([6, 7, 8, 9])]\n",
        "\n",
        "# Define parameters\n",
        "thresholds = [20, 30, 40]\n",
        "utc_labels = [\"3UTC\", \"12UTC\"]\n",
        "stats_cols = [\"Mean_Speed_knots\", \"Mean_Direction_deg\", \"Area_deg2\"]\n",
        "\n",
        "# === Step 2: Power Spectrum Analysis with Bar Plots ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df_jjas[(df_jjas[\"Threshold_knots\"] == thr) & (df_jjas[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nðŸŒŠ FFT for {thr} knots | {utc}\")\n",
        "\n",
        "        for col in stats_cols:\n",
        "            # === A. Yearly Average FFT ===\n",
        "            yearly_avg = subset.groupby(\"Year\")[col].mean().dropna()\n",
        "            if len(yearly_avg) >= 10:\n",
        "                signal = yearly_avg.values - np.mean(yearly_avg.values)\n",
        "                N = len(signal)\n",
        "                T = 1  # Yearly interval\n",
        "                freqs = fftfreq(N, T)\n",
        "                fft_vals = fft(signal)\n",
        "                power = np.abs(fft_vals[:N // 2]) ** 2\n",
        "                freqs = freqs[:N // 2]\n",
        "\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                plt.bar(freqs, power, width=0.01, color='steelblue', edgecolor='black')\n",
        "                plt.title(f\"Power Spectrum (Yearly Avg) of {col} - {thr} knots {utc}\")\n",
        "                plt.xlabel(\"Frequency (1/year)\")\n",
        "                plt.ylabel(\"Power\")\n",
        "                plt.grid(True, linestyle='--', alpha=0.5)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "            # === B. Daily Average Across All Years FFT ===\n",
        "            daily_avg = subset.groupby(\"Day\")[col].mean().dropna()\n",
        "            if len(daily_avg) >= 50:\n",
        "                signal = daily_avg.values - np.mean(daily_avg.values)\n",
        "                N = len(signal)\n",
        "                T = 1  # Daily interval\n",
        "                freqs = fftfreq(N, T)\n",
        "                fft_vals = fft(signal)\n",
        "                power = np.abs(fft_vals[:N // 2]) ** 2\n",
        "                freqs = freqs[:N // 2]\n",
        "\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                plt.bar(freqs, power, width=0.002, color='darkorange', edgecolor='black')\n",
        "                plt.title(f\"Power Spectrum (Daily Avg) of {col} - {thr} knots {utc}\")\n",
        "                plt.xlabel(\"Frequency (1/day)\")\n",
        "                plt.ylabel(\"Power\")\n",
        "                plt.grid(True, linestyle='--', alpha=0.5)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n"
      ],
      "metadata": {
        "id": "fpCf_gyjpGWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install windrose\n"
      ],
      "metadata": {
        "id": "qD0sExavt9oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from windrose import WindroseAxes\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter JJAS months from original DataFrame\n",
        "df_jjas = df[df[\"Month\"].isin([6, 7, 8, 9])]\n",
        "\n",
        "# Choose one UTC (or loop through both if needed)\n",
        "utc = \"3UTC\"  # or \"12UTC\"\n",
        "thr = 20  # or any threshold value\n",
        "\n",
        "# Subset for specific UTC and threshold\n",
        "subset = df_jjas[(df_jjas[\"UTC_Label\"] == utc) & (df_jjas[\"Threshold_knots\"] == thr)]\n",
        "if subset.empty:\n",
        "    print(\"No data found for the selected threshold and UTC.\")\n",
        "else:\n",
        "    print(f\"ðŸŒ¬ï¸ Wind Rose for JJAS | {thr} knots | {utc} | Entries: {len(subset)}\")\n",
        "\n",
        "    # Wind speed and direction arrays\n",
        "    wind_speed = subset[\"Mean_Speed_knots\"].values\n",
        "    wind_dir = subset[\"Mean_Direction_deg\"].values\n",
        "\n",
        "    # --- Create Wind Rose Plot ---\n",
        "    ax = WindroseAxes.from_ax()\n",
        "    ax.bar(wind_dir, wind_speed,\n",
        "           normed=True,\n",
        "           opening=0.8,\n",
        "           edgecolor='white',\n",
        "           bins=np.arange(0, 60, 5),  # speed bins\n",
        "           cmap=cm.viridis)\n",
        "\n",
        "    ax.set_legend(title=\"Wind Speed (knots)\")\n",
        "    plt.title(f\"JJAS Wind Rose ({thr} knots, {utc})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Compute Dominant Wind Direction ---\n",
        "    # Bin wind direction into 8 or 16 compass sectors\n",
        "    dir_bins = np.arange(0, 360 + 22.5, 22.5)  # 16 sectors\n",
        "    dir_labels = [(dir_bins[i] + dir_bins[i+1])/2 for i in range(len(dir_bins)-1)]\n",
        "    binned_dirs = pd.cut(wind_dir, bins=dir_bins, labels=dir_labels, include_lowest=True)\n",
        "\n",
        "    # Most common direction\n",
        "    dominant_dir = binned_dirs.value_counts().idxmax()\n",
        "    print(f\"ðŸ§­ Dominant Wind Direction (Â°): {dominant_dir}\")\n",
        "\n",
        "    # --- Compute Dominant Speed Bin ---\n",
        "    speed_bins = pd.cut(wind_speed, bins=np.arange(0, 60, 5))\n",
        "    dominant_speed = speed_bins.value_counts().idxmax()\n",
        "    print(f\"âš¡ Dominant Wind Speed Range: {dominant_speed}\")\n"
      ],
      "metadata": {
        "id": "N9hiqJK6uK9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from windrose import WindroseAxes\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv(\"(1963-2024).csv\")  # Replace with your file\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Filter JJAS only\n",
        "df_jjas = df[df['Date'].dt.month.isin([6, 7, 8, 9])]\n",
        "df_jjas['Year'] = df_jjas['Date'].dt.year\n",
        "\n",
        "# Extract unique years\n",
        "years = sorted(df_jjas['Year'].unique())\n",
        "n_years = len(years)\n",
        "\n",
        "# Layout: Calculate rows and cols for subplots\n",
        "ncols = 3\n",
        "nrows = -(-n_years // ncols)  # Ceiling division\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(5 * ncols, 5 * nrows))\n",
        "gs = gridspec.GridSpec(nrows, ncols)\n",
        "\n",
        "for i, year in enumerate(years):\n",
        "    row, col = divmod(i, ncols)\n",
        "    ax = WindroseAxes(fig, gs[row, col])\n",
        "    fig.add_axes(ax)\n",
        "\n",
        "    df_year = df_jjas[df_jjas['Year'] == year]\n",
        "    wind_speed = df_year['Mean_Speed_knots']\n",
        "    wind_dir = df_year['Mean_Direction_deg']\n",
        "\n",
        "    ax.bar(wind_dir, wind_speed, normed=True, opening=0.8, edgecolor='white',\n",
        "           bins=[0, 5, 10, 15, 20, 25])\n",
        "    ax.set_title(f\"JJAS {year}\", fontsize=12)\n",
        "\n",
        "# Adjust layout and add legend\n",
        "plt.tight_layout()\n",
        "fig.legend(*ax.get_legend_handles_labels(), loc='lower center', ncol=6, fontsize=10)\n",
        "plt.suptitle(\"Wind Rose Plots (JJAS) for Each Year\", fontsize=16, y=1.02)\n",
        "plt.subplots_adjust(top=0.92, bottom=0.1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JbK7xhQXuVZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Install tabulate if not already installed\n",
        "!pip install tabulate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "\n",
        "# ðŸ“‚ Load your dataset (replace 'your_file.csv' accordingly)\n",
        "# df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# ðŸ§¼ Preprocessing\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Year'] = df['Date'].dt.year\n",
        "\n",
        "# ðŸŒ¦ï¸ Filter JJAS (June to September)\n",
        "jjas_df = df[df['Month'].isin([6, 7, 8, 9])].copy()\n",
        "\n",
        "# ðŸ§­ Bin wind direction into 8 cardinal categories (N, NE, E, SE, S, SW, W, NW)\n",
        "def direction_category(deg):\n",
        "    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "    bins = np.arange(-22.5, 361, 45)\n",
        "    idx = np.digitize([deg], bins, right=True)[0] % 8\n",
        "    return directions[idx]\n",
        "\n",
        "jjas_df['Direction_Category'] = jjas_df['Mean_Direction_deg'].apply(direction_category)\n",
        "\n",
        "# âš¡ Bin wind speed\n",
        "bins = [0, 5, 10, 15, 20, 25, 30, 100]\n",
        "labels = ['(0-5]', '(5-10]', '(10-15]', '(15-20]', '(20-25]', '(25-30]', '(30+)']\n",
        "jjas_df['Speed_Range'] = pd.cut(jjas_df['Mean_Speed_knots'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# ðŸ§® Group by year, direction, and speed\n",
        "grouped = jjas_df.groupby(['Year', 'Direction_Category', 'Speed_Range']).size().reset_index(name='Frequency')\n",
        "\n",
        "# ðŸ” Find dominant direction-speed combo per year\n",
        "dominant = grouped.loc[grouped.groupby('Year')['Frequency'].idxmax()].reset_index(drop=True)\n",
        "\n",
        "# ðŸª„ Rename for clarity\n",
        "dominant.rename(columns={\n",
        "    'Direction_Category': 'Dominant_Direction',\n",
        "    'Speed_Range': 'Dominant_Speed_Range'\n",
        "}, inplace=True)\n",
        "\n",
        "# ðŸ“Š Display tabulated output\n",
        "print(tabulate(dominant, headers='keys', tablefmt='github', showindex=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "qeqcsDMuw7QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Import necessary libraries\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from google.colab import files\n",
        "\n",
        "# ðŸ“‚ Upload rainfall file\n",
        "print(\"ðŸ“‚ Upload the Rainfall CSV file:\")\n",
        "uploaded_rain = files.upload()\n",
        "rainfall_file = list(uploaded_rain.keys())[0]\n",
        "df_rain = pd.read_csv(rainfall_file)\n",
        "\n",
        "# ðŸ“‚ Upload wind speed file\n",
        "print(\"\\nðŸ“‚ Now upload the Wind Speed CSV file:\")\n",
        "uploaded_wind = files.upload()\n",
        "wind_file = list(uploaded_wind.keys())[0]\n",
        "df_wind = pd.read_csv(wind_file)\n",
        "\n",
        "# ðŸ§¹ Process wind file: extract 'year' from 'Date' and group by year\n",
        "df_wind['Date'] = pd.to_datetime(df_wind['Date'])\n",
        "df_wind['year'] = df_wind['Date'].dt.year\n",
        "wind_yearly = df_wind.groupby('year')['Mean_Speed_knots'].mean().reset_index()\n",
        "wind_yearly.rename(columns={'Mean_Speed_knots': 'WIND_SPEED'}, inplace=True)\n",
        "\n",
        "# ðŸ§¹ Process rainfall file: group by 'year'\n",
        "rain_yearly = df_rain.groupby('year')['RAINFALL'].mean().reset_index()\n",
        "\n",
        "# ðŸ”— Merge the two yearly summaries on 'year'\n",
        "merged = pd.merge(rain_yearly, wind_yearly, on='year', how='inner')\n",
        "\n",
        "# âœ… Drop missing values\n",
        "cleaned = merged.dropna(subset=[\"RAINFALL\", \"WIND_SPEED\"])\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Š CORRELATION ANALYSIS\n",
        "# ============================================\n",
        "pearson_corr, _ = pearsonr(cleaned['RAINFALL'], cleaned['WIND_SPEED'])\n",
        "spearman_corr, _ = spearmanr(cleaned['RAINFALL'], cleaned['WIND_SPEED'])\n",
        "\n",
        "print(\"\\nâœ… Correlation Results:\")\n",
        "print(f\"ðŸ“ˆ Pearson Correlation: {pearson_corr:.4f}\")\n",
        "print(f\"ðŸ“‰ Spearman Correlation: {spearman_corr:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oj6kwR7Yfr_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Import necessary libraries\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# ðŸ“‚ Upload Rainfall CSV file\n",
        "print(\"ðŸ“‚ Upload Rainfall CSV (with columns like time, RAINFALL):\")\n",
        "uploaded_rain = files.upload()\n",
        "rainfall_file = list(uploaded_rain.keys())[0]\n",
        "df_rain = pd.read_csv(rainfall_file)\n",
        "\n",
        "# ðŸ“‚ Upload Wind Speed CSV file\n",
        "print(\"\\nðŸ“‚ Upload Wind Speed CSV (with Date, Mean_Speed_knots):\")\n",
        "uploaded_wind = files.upload()\n",
        "wind_file = list(uploaded_wind.keys())[0]\n",
        "df_wind = pd.read_csv(wind_file)\n",
        "\n",
        "# ðŸ§¹ Convert 'Date' column to datetime in both\n",
        "df_rain['Date'] = pd.to_datetime(df_rain['time'])  # Replace 'time' if your column is named differently\n",
        "df_wind['Date'] = pd.to_datetime(df_wind['Date'])\n",
        "\n",
        "# ðŸ“† Add 'year' columns\n",
        "df_rain['year'] = df_rain['Date'].dt.year\n",
        "df_wind['year'] = df_wind['Date'].dt.year\n",
        "\n",
        "# ðŸ“Š Merge on 'Date'\n",
        "merged_df = pd.merge(\n",
        "    df_rain[['Date', 'RAINFALL', 'year']],\n",
        "    df_wind[['Date', 'Mean_Speed_knots']],\n",
        "    on='Date', how='inner'\n",
        ")\n",
        "\n",
        "# Rename for clarity\n",
        "merged_df.rename(columns={'Mean_Speed_knots': 'WIND_SPEED'}, inplace=True)\n",
        "\n",
        "# ðŸ“ˆ Calculate correlation for each year\n",
        "results = []\n",
        "\n",
        "for year, group in merged_df.groupby('year'):\n",
        "    if len(group) > 10:  # Avoid very small sample sizes\n",
        "        r, _ = pearsonr(group['RAINFALL'], group['WIND_SPEED'])\n",
        "        s, _ = spearmanr(group['RAINFALL'], group['WIND_SPEED'])\n",
        "        results.append({'year': year, 'pearson_corr': r, 'spearman_corr': s})\n",
        "    else:\n",
        "        results.append({'year': year, 'pearson_corr': None, 'spearman_corr': None})\n",
        "\n",
        "# ðŸ“„ Convert to DataFrame\n",
        "correlation_df = pd.DataFrame(results)\n",
        "\n",
        "# âœ… Option 1: Clean print using to_string\n",
        "print(\"\\nðŸ“Š Year-wise Correlation Analysis (using pandas to_string):\")\n",
        "print(correlation_df.to_string(index=False, float_format=\"%.6f\"))\n",
        "\n",
        "# âœ… Option 2: Pretty table using tabulate (optional)\n",
        "try:\n",
        "    from tabulate import tabulate\n",
        "    print(\"\\nðŸ“Š Year-wise Correlation Analysis (using tabulate):\")\n",
        "    print(tabulate(correlation_df, headers='keys', tablefmt='pretty', floatfmt=\".6f\"))\n",
        "except ImportError:\n",
        "    print(\"\\nðŸ”§ tabulate not installed. You can install it with: !pip install tabulate\")\n",
        "\n",
        "# ðŸ“‰ Plotting correlation trends\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(correlation_df['year'], correlation_df['pearson_corr'], marker='o', label='Pearson Correlation', color='blue')\n",
        "plt.plot(correlation_df['year'], correlation_df['spearman_corr'], marker='s', label='Spearman Correlation', color='green')\n",
        "\n",
        "plt.title('Yearly Rainfall-Wind Correlation Trends')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Correlation Coefficient')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UXBLduyhiULT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9biveTkeJ6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Import necessary libraries\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from google.colab import files\n",
        "\n",
        "# ðŸ“‚ Upload Rainfall CSV file\n",
        "print(\"ðŸ“‚ Upload Rainfall CSV (with columns like time, RAINFALL):\")\n",
        "uploaded_rain = files.upload()\n",
        "rainfall_file = list(uploaded_rain.keys())[0]\n",
        "df_rain = pd.read_csv(rainfall_file)\n",
        "\n",
        "# ðŸ“‚ Upload Wind Speed CSV file\n",
        "print(\"\\nðŸ“‚ Upload Wind Speed CSV (with Date, Mean_Speed_knots):\")\n",
        "uploaded_wind = files.upload()\n",
        "wind_file = list(uploaded_wind.keys())[0]\n",
        "df_wind = pd.read_csv(wind_file)\n",
        "\n",
        "# ðŸ§¹ Convert 'Date' column to datetime in both\n",
        "df_rain['Date'] = pd.to_datetime(df_rain['time'])  # Replace 'time' if your column is named differently\n",
        "df_wind['Date'] = pd.to_datetime(df_wind['Date'])\n",
        "\n",
        "# ðŸ“† Add 'year' columns\n",
        "df_rain['year'] = df_rain['Date'].dt.year\n",
        "df_wind['year'] = df_wind['Date'].dt.year\n",
        "\n",
        "# ðŸ“Š Merge on 'Date'\n",
        "merged_df = pd.merge(\n",
        "    df_rain[['Date', 'RAINFALL', 'year']],\n",
        "    df_wind[['Date', 'Mean_Speed_knots']],\n",
        "    on='Date', how='inner'\n",
        ")\n",
        "\n",
        "# Rename for clarity\n",
        "merged_df.rename(columns={'Mean_Speed_knots': 'WIND_SPEED'}, inplace=True)\n",
        "\n",
        "# ðŸŒ€ Function to calculate lagged correlations\n",
        "def calculate_lag_correlations(df, max_lag=3):\n",
        "    results = []\n",
        "    for year, group in df.groupby('year'):\n",
        "        if len(group) > max_lag + 10:\n",
        "            row = {'year': year}\n",
        "            for lag in range(-max_lag, max_lag + 1):  # Negative to positive lags\n",
        "                shifted = group.copy()\n",
        "                shifted['WIND_SPEED_LAG'] = shifted['WIND_SPEED'].shift(lag)\n",
        "                valid = shifted.dropna()\n",
        "\n",
        "                if len(valid) > 10:\n",
        "                    pearson_corr, _ = pearsonr(valid['RAINFALL'], valid['WIND_SPEED_LAG'])\n",
        "                    spearman_corr, _ = spearmanr(valid['RAINFALL'], valid['WIND_SPEED_LAG'])\n",
        "                    row[f'pearson_lag_{lag}'] = pearson_corr\n",
        "                    row[f'spearman_lag_{lag}'] = spearman_corr\n",
        "                else:\n",
        "                    row[f'pearson_lag_{lag}'] = None\n",
        "                    row[f'spearman_lag_{lag}'] = None\n",
        "            results.append(row)\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# ðŸƒ Filter only monsoon months (June to September)\n",
        "merged_df = merged_df[merged_df['Date'].dt.month.isin([6, 7, 8, 9])]\n",
        "\n",
        "# ðŸ“ˆ Now calculate lagged correlation for filtered data\n",
        "correlation_df = calculate_lag_correlations(merged_df, max_lag=3)\n",
        "\n",
        "\n",
        "# ðŸ“‹ Reorder columns: first all Pearson lags, then all Spearman lags\n",
        "pearson_cols = [col for col in correlation_df.columns if col.startswith('pearson_lag_')]\n",
        "spearman_cols = [col for col in correlation_df.columns if col.startswith('spearman_lag_')]\n",
        "ordered_cols = ['year'] + sorted(pearson_cols, key=lambda x: int(x.split('_')[-1])) + sorted(spearman_cols, key=lambda x: int(x.split('_')[-1]))\n",
        "correlation_df = correlation_df[ordered_cols]\n",
        "\n",
        "# âœ… Option 1: Clean print using to_string\n",
        "print(\"\\nðŸ“Š Year-wise Lag Correlation Analysis (using pandas to_string):\")\n",
        "print(correlation_df.to_string(index=False, float_format=\"%.6f\"))\n",
        "\n",
        "# âœ… Option 2: Pretty table using tabulate (optional)\n",
        "try:\n",
        "    from tabulate import tabulate\n",
        "    print(\"\\nðŸ“Š Year-wise Lag Correlation Analysis (using tabulate):\")\n",
        "    print(tabulate(correlation_df, headers='keys', tablefmt='pretty', floatfmt=\".6f\"))\n",
        "except ImportError:\n",
        "    print(\"\\nðŸ”§ tabulate not installed. You can install it with: !pip install tabulate\")\n",
        "\n",
        "# ðŸ“Š Plotting setup\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ðŸŒˆ Convert DataFrame to long format for heatmap\n",
        "def prepare_heatmap_data(df, method='pearson'):\n",
        "    heatmap_df = df.copy()\n",
        "    id_vars = ['year']\n",
        "    value_vars = [col for col in df.columns if col.startswith(f'{method}_lag_')]\n",
        "\n",
        "    melted = pd.melt(heatmap_df, id_vars=id_vars, value_vars=value_vars,\n",
        "                     var_name='lag', value_name='correlation')\n",
        "\n",
        "    # Extract numeric lag values\n",
        "    melted['lag'] = melted['lag'].str.extract(r'lag_(-?\\d+)').astype(int)\n",
        "\n",
        "    # Pivot to make heatmap\n",
        "    pivot_df = melted.pivot(index='year', columns='lag', values='correlation')\n",
        "    return pivot_df\n",
        "\n",
        "# ðŸ”¥ Plot heatmaps\n",
        "for method in ['pearson', 'spearman']:\n",
        "    heatmap_data = prepare_heatmap_data(correlation_df, method=method)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(heatmap_data, annot=True, center=0, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title(f'{method.capitalize()} Lag Correlation: Rainfall vs Wind Speed')\n",
        "    plt.xlabel(\"Lag (days)\")\n",
        "    plt.ylabel(\"Year\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ðŸ“Š Bar plot of average lag correlation across years\n",
        "def plot_avg_lag_correlation(df, method='pearson'):\n",
        "    avg_corr = {}\n",
        "    for col in df.columns:\n",
        "        if col.startswith(f'{method}_lag_'):\n",
        "            avg_corr[col] = df[col].mean()\n",
        "\n",
        "    # Convert to sorted DataFrame\n",
        "    lag_df = pd.DataFrame({\n",
        "        'Lag': [int(k.split('_lag_')[1]) for k in avg_corr.keys()],\n",
        "        'Avg_Correlation': list(avg_corr.values())\n",
        "    }).sort_values('Lag')\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(data=lag_df, x='Lag', y='Avg_Correlation', palette='coolwarm')\n",
        "    plt.title(f\"Average {method.capitalize()} Lag Correlation (All Years)\")\n",
        "    plt.axhline(0, color='black', linestyle='--')\n",
        "    plt.xlabel(\"Lag (days)\")\n",
        "    plt.ylabel(\"Average Correlation\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ðŸ“Š Average correlation bar plots\n",
        "plot_avg_lag_correlation(correlation_df, method='pearson')\n",
        "plot_avg_lag_correlation(correlation_df, method='spearman')\n",
        "\n",
        "# ðŸ“ˆ Line plot of lag correlation per year\n",
        "def plot_lag_correlation_lines(df, method='pearson'):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        year = row['year']\n",
        "        lags = []\n",
        "        values = []\n",
        "        for col in row.index:\n",
        "            if col.startswith(f'{method}_lag_'):\n",
        "                lag = int(col.split('_lag_')[1])\n",
        "                lags.append(lag)\n",
        "                values.append(row[col])\n",
        "        plt.plot(lags, values, marker='o', label=str(year))\n",
        "\n",
        "    plt.title(f\"{method.capitalize()} Lag Correlation by Year\")\n",
        "    plt.xlabel(\"Lag (days)\")\n",
        "    plt.ylabel(\"Correlation\")\n",
        "    plt.axhline(0, color='gray', linestyle='--')\n",
        "    plt.grid(True)\n",
        "    plt.legend(title=\"Year\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ðŸ“ˆ Line plots\n",
        "plot_lag_correlation_lines(correlation_df, method='pearson')\n",
        "plot_lag_correlation_lines(correlation_df, method='spearman')\n"
      ],
      "metadata": {
        "id": "E25uti7OkwDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSsViLu7kuxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“¦ Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# ðŸ“‚ Upload Rainfall CSV file\n",
        "print(\"ðŸ“‚ Upload Rainfall CSV (with columns like time, RAINFALL):\")\n",
        "uploaded_rain = files.upload()\n",
        "rainfall_file = list(uploaded_rain.keys())[0]\n",
        "df_rain = pd.read_csv(rainfall_file)\n",
        "\n",
        "# ðŸ“‚ Upload Wind Speed CSV file\n",
        "print(\"\\nðŸ“‚ Upload Wind Speed CSV (with Date, Mean_Speed_knots):\")\n",
        "uploaded_wind = files.upload()\n",
        "wind_file = list(uploaded_wind.keys())[0]\n",
        "df_wind = pd.read_csv(wind_file)\n",
        "\n",
        "# ðŸ§¹ Convert date columns to datetime format\n",
        "df_rain['Date'] = pd.to_datetime(df_rain['time'])  # Adjust if column name differs\n",
        "df_wind['Date'] = pd.to_datetime(df_wind['Date'])\n",
        "\n",
        "# ðŸ“Š Merge datasets on 'Date'\n",
        "merged_df = pd.merge(\n",
        "    df_rain[['Date', 'RAINFALL']],\n",
        "    df_wind[['Date', 'Mean_Speed_knots']],\n",
        "    on='Date', how='inner'\n",
        ")\n",
        "\n",
        "# âœ… Rename for clarity\n",
        "merged_df.rename(columns={'Mean_Speed_knots': 'WIND_SPEED'}, inplace=True)\n",
        "\n",
        "# ðŸ“ˆ Plot time-series comparison\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Rainfall\n",
        "plt.plot(merged_df['Date'], merged_df['RAINFALL'], label='Rainfall (mm)', color='blue', alpha=0.6)\n",
        "\n",
        "# Plot Wind Speed on secondary y-axis\n",
        "plt.plot(merged_df['Date'], merged_df['WIND_SPEED'], label='Wind Speed (knots)', color='green', alpha=0.6)\n",
        "\n",
        "# ðŸ–¼ï¸ Final touches\n",
        "plt.title('ðŸ“ˆ Time-Series: Rainfall vs Wind Speed')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "htDJyz6PsRge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 0: Imports and Upload CSV ===\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.fft import fft, fftfreq\n",
        "from collections import defaultdict\n",
        "\n",
        "# Upload your CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# === Step 1: Load and Preprocess ===\n",
        "input_csv = \"(1963-2024).csv\"\n",
        "df = pd.read_csv(input_csv, parse_dates=[\"Date\"])\n",
        "print(\"âœ… Loaded data from\", input_csv)\n",
        "\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "df[\"Decade\"] = (df[\"Year\"] // 10) * 10\n",
        "\n",
        "# Define thresholds and labels\n",
        "thresholds = [20, 30, 40]\n",
        "utc_labels = [\"3UTC\", \"12UTC\"]\n",
        "stats_cols = [\"Mean_Speed_knots\", \"Mean_Direction_deg\", \"Area_deg2\"]\n",
        "\n",
        "# Store summary\n",
        "stats_summary = defaultdict(dict)\n",
        "\n",
        "# === Step 2: Monthly and Seasonal Plots (using all months) ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== {thr} knots | {utc} ===\")\n",
        "\n",
        "        # Monthly Averages\n",
        "        monthly_avg = subset.groupby(\"Month\")[stats_cols].mean()\n",
        "\n",
        "        # A. Monthly Wind Speed Variation (Bar Chart)\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(monthly_avg.index, monthly_avg[\"Mean_Speed_knots\"], color='skyblue', edgecolor='black')\n",
        "        plt.title(f\"Monthly Mean Wind Speed (All Months) - {thr} knots {utc}\")\n",
        "        plt.xlabel(\"Month\")\n",
        "        plt.ylabel(\"Mean Wind Speed (knots)\")\n",
        "        plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"])\n",
        "        plt.grid(axis='y')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Regular monthly line plots\n",
        "        for col in stats_cols:\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(monthly_avg.index, monthly_avg[col], marker='o')\n",
        "            plt.title(f\"{col} Monthly Avg (All Months) - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Month\")\n",
        "            plt.ylabel(col)\n",
        "            plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"])\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Seasonal Boxplots (per year)\n",
        "        for col in stats_cols:\n",
        "            season_data = subset.groupby(\"Year\")[col].apply(list).dropna()\n",
        "\n",
        "            plt.figure(figsize=(16, 6))\n",
        "            plt.boxplot(season_data,\n",
        "                        positions=season_data.index,\n",
        "                        widths=0.8,\n",
        "                        patch_artist=True,\n",
        "                        boxprops=dict(facecolor='lightblue'),\n",
        "                        medianprops=dict(color='red', linewidth=2),\n",
        "                        whiskerprops=dict(linewidth=1.5),\n",
        "                        capprops=dict(linewidth=1.5),\n",
        "                        flierprops=dict(marker='o', markersize=4, markerfacecolor='gray'))\n",
        "\n",
        "            plt.title(f\"Seasonal Boxplot of {col} (All Months) - {thr} knots {utc}\", fontsize=14)\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(col)\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# === Step 3: Spectral (FFT) Analysis ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        for col in stats_cols:\n",
        "            yearly_mean = subset.groupby(\"Year\")[col].mean().dropna()\n",
        "            if yearly_mean.empty or len(yearly_mean) < 10:\n",
        "                continue\n",
        "\n",
        "            signal = yearly_mean.values\n",
        "            N = len(signal)\n",
        "            T = 1  # 1 year interval\n",
        "            freqs = fftfreq(N, T)\n",
        "            fft_vals = fft(signal)\n",
        "\n",
        "            power = np.abs(fft_vals[:N//2]) ** 2\n",
        "            freqs = freqs[:N//2]\n",
        "\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(freqs, power)\n",
        "            plt.title(f\"Power Spectrum of {col} - {thr} knots {utc}\")\n",
        "            plt.xlabel(\"Frequency (1/year)\")\n",
        "            plt.ylabel(\"Power\")\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Dominant Oscillation\n",
        "            dominant_freq = freqs[np.argmax(power)]\n",
        "            period = 1 / dominant_freq if dominant_freq != 0 else float('inf')\n",
        "            print(f\"ðŸ” Dominant Period for {col} ({thr} knots, {utc}): ~{period:.2f} years\")\n",
        "\n",
        "# === Step 4: Overall Variance Report ===\n",
        "for thr in thresholds:\n",
        "    for utc in utc_labels:\n",
        "        subset = df[(df[\"Threshold_knots\"] == thr) & (df[\"UTC_Label\"] == utc)]\n",
        "        if not subset.empty:\n",
        "            stats_summary[(thr, utc)][\"Overall Variance\"] = subset[stats_cols].var()\n",
        "\n",
        "print(\"\\nðŸ“ˆ OVERALL VARIANCE (entire dataset per threshold and UTC):\")\n",
        "for key, val in stats_summary.items():\n",
        "    thr, utc = key\n",
        "    print(f\"\\nâš¡ {thr} knots | {utc}:\")\n",
        "    print(val[\"Overall Variance\"])\n"
      ],
      "metadata": {
        "id": "tkYcR1Ic8A_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "# --- Step 1: Upload CSV ---\n",
        "#print(\"Please upload your rainfall CSV file...\")\n",
        "#uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# --- Step 2: Load and prepare data ---\n",
        "df = pd.read_csv(filename)\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "df['RAINFALL'] = pd.to_numeric(df['RAINFALL'], errors='coerce')\n",
        "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "df['month'] = df['time'].dt.month\n",
        "df['day'] = df['time'].dt.day\n",
        "\n",
        "print(\"\\nData preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# --- Step 3: Overall stats ---\n",
        "overall_mean = df['RAINFALL'].mean()\n",
        "overall_std = df['RAINFALL'].std()\n",
        "\n",
        "# --- Step 4: Seasonal stats (per month) ---\n",
        "monthly_stats = df.groupby('month')['RAINFALL'].agg(['mean','std']).reset_index()\n",
        "\n",
        "# Merge stats back to dataframe\n",
        "df = df.merge(monthly_stats, on='month', how='left', suffixes=('', '_month'))\n",
        "\n",
        "# --- Step 5: Anomaly detection ---\n",
        "# Seasonal anomaly: deviation from that month's historical mean\n",
        "df['Deviation'] = df['RAINFALL'] - df['mean']\n",
        "df['Percent_Deviation'] = (df['Deviation'] / df['mean']) * 100\n",
        "df['Seasonal_Anomaly'] = ((df['RAINFALL'] > df['mean'] + 2*df['std']) |\n",
        "                          (df['RAINFALL'] < df['mean'] - 2*df['std']))\n",
        "\n",
        "# --- Step 6: JJAS (Monsoon) stats ---\n",
        "df['season'] = np.where(df['month'].isin([6,7,8,9]), 'JJAS', 'Other')\n",
        "season_stats = df.groupby('season')['RAINFALL'].agg(['mean','std']).reset_index()\n",
        "df = df.merge(season_stats, on='season', how='left', suffixes=('', '_season'))\n",
        "\n",
        "df['JJAS_Anomaly'] = np.where(\n",
        "    df['season'] == 'JJAS',\n",
        "    ((df['RAINFALL'] > df['mean_season'] + 2*df['std_season']) |\n",
        "     (df['RAINFALL'] < df['mean_season'] - 2*df['std_season'])),\n",
        "    False\n",
        ")\n",
        "\n",
        "# --- Step 7: Save anomalies ---\n",
        "seasonal_anomalies = df[df['Seasonal_Anomaly'] | df['JJAS_Anomaly']]\n",
        "seasonal_anomalies.to_csv(\"seasonal_rainfall_anomalies.csv\", index=False)\n",
        "print(\"\\nSeasonal anomalies saved to seasonal_rainfall_anomalies.csv\")\n",
        "files.download(\"seasonal_rainfall_anomalies.csv\")\n",
        "\n",
        "# --- Step 8: Visualization ---\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(x='time', y='RAINFALL', data=df, label='Rainfall')\n",
        "sns.scatterplot(x='time', y='RAINFALL', data=seasonal_anomalies, color='red', label='Anomalies')\n",
        "plt.title(\"Rainfall with Seasonal & JJAS Anomalies\")\n",
        "plt.axhline(overall_mean, color='green', linestyle='--', label='Overall Mean')\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Rainfall\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Step 9: Monthly deviation heatmap ---\n",
        "plt.figure(figsize=(12,6))\n",
        "monthly_dev = monthly_stats.set_index('month')['mean'] - overall_mean\n",
        "sns.heatmap(monthly_dev.to_frame().T, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title(\"Monthly Mean Deviation from Overall Mean Rainfall\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H9kDDw7kdMCI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}